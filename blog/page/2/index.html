
<!DOCTYPE HTML>
<html>
<head>
	<meta charset="utf-8">
	<title>首页 - The Hard Way Is Easier</title>
    <meta name="author" content="linuxfish">
    
	<meta name="description" content="Published on: Nov 26th, 2017 Tags: 问题的起因是想知道在Django ORM中如何处理大数据集的返回，比如怎么避免进程由于内存占用过多被kill掉。由于数据库使用的是MySQL，讨论是从MySQL开始的。 MySQL协议是半双工的，同一时间只能有一方在说话， &hellip;">
	
	<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

	<link href="/atom.xml" rel="alternate" title="The Hard Way Is Easier" type="application/atom+xml">
	<link rel="canonical" href="">
	<link href="/favicon.ico" rel="shortcut icon">
    <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">

    <link href='http://fonts.googleapis.com/css?family=Slackey' rel='stylesheet' type='text/css'>
    <!--<link href='http://fonts.useso.com/css?family=Slackey' rel='stylesheet' type='text/css'> -->
    <link href='http://fonts.googleapis.com/css?family=Fjalla+One' rel='stylesheet' type='text/css'>
    <!--<link href='http://fonts.useso.com/css?family=Fjalla+One' rel='stylesheet' type='text/css'> -->
    <link href='http://fonts.googleapis.com/css?family=Amethysta' rel='stylesheet' type='text/css'>
    <!--<link href='http://fonts.useso.com/css?family=Amethysta' rel='stylesheet' type='text/css'> -->
    <script src="//ajax.googleapis.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script>
    <!--<script src="http://ajax.useso.com/ajax/libs/jquery/1.8.2/jquery.min.js"></script> -->
    <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

    <script type="text/javascript" src="/javascripts/jquery-tapir.js"></script>

    <!-- remove or comment it to disable ajaxification -->   
    <script src="/javascripts/ajaxify.js"></script>
   
    
    

</head>


<body>
    <div id="wrapper">
    <header id="header" class="inner"><!-- for more effects see _animate.scss -->
<h1 class="animated bounceInDown">
    <div id="headerbg">
        linuxfish
    </div>
</h1>
<br>

<ul id="social-links" style="text-align:center">
  
  <!-- GitHub -->
  <li>
  <a href="https://github.com/cs50mu" class="github" title="Github"></a>
  </li>
  
  
  <!-- Google Plus -->
  <li>
  <a href="http://plus.google.com/linuxfish.exe@gmail.com?rel=author" class="google" title="Google+"></a>
  </li>
  
  
  
  <!-- Twitter -->
  <li>
  <a href="http://www.twitter.com/linuxfish" class="twitter" title="Twitter"></a>
  </li>
  
  
  
  
  
</ul>


<!-- use full url including 'index.html' for navigation bar if you are using ajax -->
<ul id="nav">
	<li id="ajax"><a href="/index.html">Home</a></li>
	<li id="ajax"><a href="/blog/archives/index.html">Archives</a></li>
    <li><a href="/atom.xml">RSS</a></li>
    
    <li>
    <div id="dark">
        <form method="get" action="/search.html" id="search">
            <input name="query" type="text" placeholder="Search..." x-webkit-speech />
        </form>
    </div>
    </li>
        
</ul>




</header>

<div id="toload">
<!-- begin toload --> 
    <div id="content" class="inner">
        


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/11/26/big-resultsets-handling-in-django/">
		
			如何处理数据库大结果集?</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2017-11-26T23:57:00+08:00" pubdate data-updated="true">Nov 26<span>th</span>, 2017</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<p>问题的起因是想知道在Django ORM中如何处理大数据集的返回，比如怎么避免进程由于内存占用过多被kill掉。由于数据库使用的是MySQL，讨论是从MySQL开始的。</p>

<p>MySQL协议是半双工的，同一时间只能有一方在说话，一旦服务器开始返回数据，客户端能做的只能是把数据接收完，不存在让服务器停止这一说。。（因为还没轮到它说嘛。。）所以，写sql的时候注意加limit是很重要的！</p>

<p>那么对于一次sql查询的返回，MySQL客户端有两个选择：</p>

<p>1、MySQL客户端默认会一次性先把服务器返回的数据先缓存起来，再给它的客户去用。这样做的好处是，能尽快解放数据库相关线程，让它们去做更重要的事，比如服务其它请求（因为服务器通常需要等所有数据都发送完后才释放这条查询相关的资源的），坏处是如果返回的结果很大，客户端需要花费很多时间和内存来接收它，更气人的是，在这期间，做为客户端的用户，你啥也干不了，只能等。</p>

<p>2、MySQL客户端还有一个选择，就是不自己先缓存啦，一边从server接收一边就返回给它的用户了~这样做的好处是，对于MySQL客户端的用户来说，它看起来反应更快了（因为没有先缓存所有数据集），而且貌似还便于做内存占用的优化？比如一边接收、处理，一边删除已处理过的数据，使得内存占用始终保持在一个很小的数量。坏处是有一个处理很慢的用户可能会拖垮数据库，并且在接收完之前客户端不能做任何其它的事情！这其实是一个Unbuffered Cursor，在MySQL客户端实现里叫SSCursor，即server side cursor，但其实它不是真正的server side cursor</p>

<p>Django ORM的queryset在被使用的时候会触发对应sql查询被执行，像上面说的，默认情况下结果集会被客户端先缓存，这已经是一个内存占用，然后会被Django转成对应的model instance，这又是一个内存占用，如果内存没有被及时回收，这其实是一份数据的双倍内存占用。</p>

<p>queryset的一个方法iterator能实现的一个优化是，将数据集转成model instance的过程改为generator模式，减少第二步的内存占用（注意：这只是针对MySQL来说的）</p>

<p>对于会返回大数据集的查询，一个处理办法是拆分使用limit来多次接收。每次接收一定量的数据（比如1000），内存回收后再接收下一个1000，对应的Django实现：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">import</span> <span class="nn">gc</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">queryset_iterator</span><span class="p">(</span><span class="n">queryset</span><span class="p">,</span> <span class="n">chunksize</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
</span><span class='line'>    <span class="sd">&#39;&#39;&#39;&#39;&#39;</span>
</span><span class='line'><span class="sd">    Iterate over a Django Queryset ordered by the primary key</span>
</span><span class='line'>
</span><span class='line'><span class="sd">    This method loads a maximum of chunksize (default: 1000) rows in it&#39;s</span>
</span><span class='line'><span class="sd">    memory at the same time while django normally would load all rows in it&#39;s</span>
</span><span class='line'><span class="sd">    memory. Using the iterator() method only causes it to not preload all the</span>
</span><span class='line'><span class="sd">    classes.</span>
</span><span class='line'>
</span><span class='line'><span class="sd">    Note that the implementation of the iterator does not support ordered query sets.</span>
</span><span class='line'><span class="sd">    &#39;&#39;&#39;</span>
</span><span class='line'>    <span class="n">pk</span> <span class="o">=</span> <span class="mi">0</span>
</span><span class='line'>    <span class="n">last_pk</span> <span class="o">=</span> <span class="n">queryset</span><span class="o">.</span><span class="n">order_by</span><span class="p">(</span><span class="s">&#39;-pk&#39;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">pk</span>
</span><span class='line'>    <span class="n">queryset</span> <span class="o">=</span> <span class="n">queryset</span><span class="o">.</span><span class="n">order_by</span><span class="p">(</span><span class="s">&#39;pk&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="k">while</span> <span class="n">pk</span> <span class="o">&lt;</span> <span class="n">last_pk</span><span class="p">:</span>
</span><span class='line'>        <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">queryset</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">pk__gt</span><span class="o">=</span><span class="n">pk</span><span class="p">)[:</span><span class="n">chunksize</span><span class="p">]:</span>
</span><span class='line'>            <span class="n">pk</span> <span class="o">=</span> <span class="n">row</span><span class="o">.</span><span class="n">pk</span>
</span><span class='line'>            <span class="k">yield</span> <span class="n">row</span>
</span><span class='line'>        <span class="n">gc</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
</span></code></pre></td></tr></table></div></figure>


<p>参考：</p>

<ul>
<li><a href="https://stackoverflow.com/questions/4856882/limiting-memory-use-in-a-large-django-queryset?rq=1">https://stackoverflow.com/questions/4856882/limiting-memory-use-in-a-large-django-queryset?rq=1</a></li>
<li><a href="https://stackoverflow.com/questions/14144408/memory-efficient-constant-and-speed-optimized-iteration-over-a-large-table-in?noredirect=1&amp;lq=1">https://stackoverflow.com/questions/14144408/memory-efficient-constant-and-speed-optimized-iteration-over-a-large-table-in?noredirect=1&amp;lq=1</a></li>
<li><a href="https://djangosnippets.org/snippets/1949/">https://djangosnippets.org/snippets/1949/</a></li>
<li><a href="https://docs.djangoproject.com/en/1.11/ref/models/querysets/#iterator">https://docs.djangoproject.com/en/1.11/ref/models/querysets/#iterator</a></li>
</ul>


<p>下面讲一下真正的server side cursor，postgresql支持真正意义上的server side cursor，可以给一个查询指定一个cursor，然后在这个cursor上操作，fetch多行、move(移动）cursor、更新当前cursor所在的记录等等，可参考<a href="https://www.postgresql.org/docs/9.2/static/plpgsql-cursors.html">文档</a>。看MySQL<a href="https://dev.MySQL.com/doc/refman/5.7/en/cursors.html">官方文档</a>，它也支持一个很简陋的server side cursor，而且只能在存储过程里用。</p>

<p>顺便，google到一个对比Client-Side Cursors和Server-Side Cursors区别的文档，竟然来自微软。。</p>

<p>Client-Side Cursors</p>

<p>With a non-keyset client-side cursor, the server sends the entire result set across the network to the client machine. The client machine provides and manages the temporary resources needed by the cursor and result set. The client-side application can browse through the entire result set to determine which rows it requires.</p>

<p>Static and keyset-driven client-side cursors may place a significant load on your workstation if they include too many rows. While all of the cursor libraries are capable of building cursors with thousands of rows, applications designed to fetch such large rowsets may perform poorly. There are exceptions, of course. For some applications, a large client-side cursor may be perfectly appropriate and performance may not be an issue.</p>

<p>One obvious benefit of the client-side cursor is quick response. After the result set has been downloaded to the client machine, browsing through the rows is very fast. Your application is generally more scalable with client-side cursors because the cursor&rsquo;s resource requirements are placed on each separate client and not on the server.</p>

<p>Server-Side Cursors</p>

<p>With a server-side cursor, the server manages the result set using resources provided by the server machine. The server-side cursor returns only the requested data over the network. This type of cursor can sometimes provide better performance than the client-side cursor, especially in situations where excessive network traffic is a problem.</p>

<p>Server-side cursors also permit more than one operation on the connection. That is, once you create the cursor, you can use the same connection to make changes to the rows — without having to establish an additional connection to handle the underlying update queries.</p>

<p>However, it&rsquo;s important to point out that a server-side cursor is — at least temporarily — consuming precious server resources for every active client. You must plan accordingly to ensure that your server hardware is capable of managing all of the server-side cursors requested by active clients. Also, a server-side cursor can be slow because it provides only single row access — there is no batch cursor available.</p>

<p>Server-side cursors are useful when inserting, updating, or deleting records. With server-side cursors, you can have multiple active statements on the same connection. With SQL Server, you can have pending results in multiple statement handles.</p>

<p>参考：</p>

<ul>
<li><a href="https://msdn.microsoft.com/en-us/library/aa266531(v=vs.60">Client-Side Cursors Versus Server-Side Cursors</a>.aspx)</li>
<li><a href="http://thebuild.com/blog/2010/12/13/very-large-result-sets-in-django-using-postgresql/">Very Large Result Sets in Django using PostgreSQL</a></li>
<li><a href="https://www.postgresql.org/docs/9.2/static/plpgsql-cursors.html">postgresql cursors</a></li>
<li><a href="http://techualization.blogspot.com/2011/12/retrieving-million-of-rows-from-MySQL.html">Retrieving million of rows from MySQL</a></li>
<li><a href="https://dev.MySQL.com/doc/refman/5.7/en/cursors.html">MySQL cursors</a></li>
<li><a href="https://code.djangoproject.com/ticket/16614#no1">Django中对server side cursor的支持</a></li>
</ul>


		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2017/11/26/big-resultsets-handling-in-django//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/10/15/chunked-encoding-and-wsgi/">
		
			Chunked Encoding and Wsgi</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2017-10-15T15:58:00+08:00" pubdate data-updated="true">Oct 15<span>th</span>, 2017</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<p>记录一次问题定位过程。</p>

<p>一天，接到业务组的同学反馈：“你们的某个服务在仿真环境不可用了”。看到报错信息后我第一反应就是，是他们传递的参数有误，因为：1. 近期代码没有改动，只是由ECS
部署改为了Docker部署；2. 报错信息提示post的json数据有问题。</p>

<p>然而，跟业务组同学反复确认后发现，他们post的数据并没有错。。进一步定位后发现，原来不是post参数有误，而是应用里读取到的post data为空了！</p>

<p>跑到运维同学那里，进入容器环境用tcpdump抓了下包，发现进入应用框架(Django)之前post数据还是在的。。</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>tcpdump -l -s 0 -w - dst port 5000 | strings</span></code></pre></td></tr></table></div></figure>


<p>抓包数据如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>POST /api/purchases/ HTTP/1.1
</span><span class='line'>Host: jccoin.dev.igetget.com
</span><span class='line'>User-Agent: Go-http-client/1.1
</span><span class='line'>Transfer-Encoding: chunked
</span><span class='line'>Content-Type: application/json
</span><span class='line'>Accept-Encoding: gzip
</span><span class='line'>X-Forwarded-For: 10.30.47.54
</span><span class='line'>Connection: close
</span><span class='line'>{"purchase_no":"b7eb4vd86rijdi8i5sa0","category":2,"sys_code":"IGET","buyer_id":"21075408","device_type":"ANDROID","product_category":"53","product_id":"1","product_name":"
</span><span class='line'>","coins_amount":335,"tag":"","sign":"ffc88ffc0b0aaf191d11b0909575f40c"}</span></code></pre></td></tr></table></div></figure>


<p>但是，这怎么可能？！</p>

<p>切换回ECS环境后接口恢复正常了，于是在ECS环境重新抓包如下：</p>

<p>ECS环境上应用框架(Django)前有一个nginx，进入nginx前的包数据如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>POST /api/purchases/ HTTP/1.1
</span><span class='line'>Host: jccoin.dev.igetget.com
</span><span class='line'>User-Agent: Go-http-client/1.1
</span><span class='line'>Transfer-Encoding: chunked
</span><span class='line'>Content-Type: application/json
</span><span class='line'>Accept-Encoding: gzip
</span><span class='line'>{"purchase_no":"b7ep9jt86rik99q3q6eg","category":2,"sys_code":"IGET","buyer_id":"645563","device_type":"ANDROID","product_category":"55","product_id":"2","product_name":"30
</span><span class='line'>","coins_amount":48,"tag":"30","sign":"68fff62307beec83399933c5d2bd278d"}</span></code></pre></td></tr></table></div></figure>


<p>从nginx出来，进入应用框架(Django)之前的包数据如下：</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>POST /api/purchases/ HTTP/1.0
</span><span class='line'>Host: jccoin.dev.igetget.com
</span><span class='line'>X-Real-IP: 10.30.47.54
</span><span class='line'>X-Forwarded-For: 10.30.47.54
</span><span class='line'>Connection: close
</span><span class='line'>Content-Length: 263
</span><span class='line'>User-Agent: Go-http-client/1.1
</span><span class='line'>Content-Type: application/json
</span><span class='line'>Accept-Encoding: gzip
</span><span class='line'>{"purchase_no":"b7ep9jt86rik99q3q6eg","category":2,"sys_code":"IGET","buyer_id":"645563","device_type":"ANDROID","product_category":"55","product_id":"2","product_name":"30
</span><span class='line'>","coins_amount":48,"tag":"30","sign":"68fff62307beec83399933c5d2bd278d"}</span></code></pre></td></tr></table></div></figure>


<p>可以看到，经过nginx后数据由chunked变成了content-length。</p>

<p>从上面的情况猜测应用框架对chunked encoding支持有问题，一番google后发现果然如此:</p>

<ul>
<li><a href="https://stackoverflow.com/questions/12091067/handling-http-chunked-encoding-with-django">https://stackoverflow.com/questions/12091067/handling-http-chunked-encoding-with-django</a></li>
<li><a href="https://github.com/pallets/flask/issues/2229">https://github.com/pallets/flask/issues/2229</a></li>
<li><a href="http://mathslinux.org/?p=564">http://mathslinux.org/?p=564</a></li>
<li><p><a href="https://twitter.com/davidism/status/888426616602230784">https://twitter.com/davidism/status/888426616602230784</a></p></li>
<li><p><a href="http://lucumr.pocoo.org/2011/7/27/the-pluggable-pipedream/">http://lucumr.pocoo.org/2011/7/27/the-pluggable-pipedream/</a></p></li>
<li><a href="https://www.python.org/dev/peps/pep-0333/#handling-the-content-length-header">https://www.python.org/dev/peps/pep-0333/#handling-the-content-length-header</a></li>
<li><a href="http://rhodesmill.org/brandon/2013/chunked-wsgi/">http://rhodesmill.org/brandon/2013/chunked-wsgi/</a></li>
</ul>


<p>所以这么看来，Django这一类框架在前面挂一个nginx是必须的。</p>

		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2017/10/15/chunked-encoding-and-wsgi//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/03/20/zhihu-authentication-analysis/">
		
			Zhihu Authentication Analysis</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2017-03-20T09:39:00+08:00" pubdate data-updated="true">Mar 20<span>th</span>, 2017</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<h2>知乎以及得到手机App与Server端的认证机制分析</h2>

<h3>抓包</h3>

<p>采用Charles进行抓包</p>

<ul>
<li>一个关键点是如何抓SSL包

<ul>
<li><a href="https://www.charlesproxy.com/documentation/using-charles/ssl-certificates/">https://www.charlesproxy.com/documentation/using-charles/ssl-certificates/</a></li>
</ul>


<p>  需要在手机上安装Charles自己的证书，但注意<strong>从Android N开始，必须在手机App的配置文件里显式的指定信任Charles的根证书才行。</strong></p></li>
</ul>


<p>在分析得到App与Server端的交互时发现，几乎每个链接都会带一个sign参数，如果不传递这个参数的话，Server端会返回错误，那么这个sign参数是从哪里来的呢？这个时候就需要反编译一下APK来分析一下了。</p>

<h3>逆向APK</h3>

<p>逆向APK所用到的工具主要是Jadx，有时可能还需要Hopper Dissembler，下面会详细介绍</p>

<ul>
<li><p>Jadx</p>

<p>  来自GitHub首页的介绍：Command line and GUI tools for produce Java source code from Android Dex and Apk files，非常简单易用，<strong>反编译的时候记得在配置里把反混淆勾上。</strong></p>

<p>  反编译完成后，可以直接在jadx-gui里浏览源代码，也可以导入Android Studio里查看，再配合一些关键字用grep在命令行定位代码不要太爽啊~~~</p></li>
</ul>


<p>在分析反编译出来的代码过程中发现，某个关键的函数找不到定义的地方，样子如下：</p>

<pre><code>    public static native String keyBaseFromJNI();
</code></pre>

<p>一番搜索后发现，这种写法是调用了C或者C++写的底层库文件（比如so或者dll文件），这样做的原因显然是：1. 效率更高；2. 增加破解难度。下面就该反汇编大神出场了。</p>

<ul>
<li><p>Hopper Dissembler</p>

<p>  Hopper is a tool that will assist you in your static analysis of executable files.</p>

<ul>
<li><a href="https://www.hopperapp.com/tutorial.html">https://www.hopperapp.com/tutorial.html</a></li>
<li><a href="https://bestswifter.com/app-crack/">https://bestswifter.com/app-crack/</a></li>
<li><a href="http://www.10tiao.com/html/410/201701/2656257139/1.html">http://www.10tiao.com/html/410/201701/2656257139/1.html</a></li>
</ul>


<p>  直接把从APK中提取出的so文件导入Hopper Dissembler即可，注意这个工具最牛逼的一点是可以生成C伪代码。</p></li>
<li>TODO

<ul>
<li>搞明白混淆是怎么做的</li>
<li>为啥反编译后的代码有些是正常的，有些变量名已经被改成乱码了，基本不可读</li>
</ul>
</li>
</ul>


<p>分析知乎客户端与Server认证机制时遇到一个签名算法HMAC，顺便把各种签名算法学习一下</p>

<h3>签名算法</h3>

<ul>
<li>hmac-sha1</li>
<li>md5</li>
<li>sha1</li>
<li>各种算法的优缺点</li>
</ul>


<p>to be continued</p>

		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2017/03/20/zhihu-authentication-analysis//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/02/22/process-data-using-awk/">
		
			Process Data Using Awk</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2017-02-22T15:18:00+08:00" pubdate data-updated="true">Feb 22<span>nd</span>, 2017</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<h3>AWK学习笔记</h3>

<p>以下内容主要参考自《The AWK Programming Language》一书以及GNU的《The GNU Awk User’s Guide》。</p>

<ul>
<li><p>the structure of an AWK program</p>

<pre><code>  pattern { action }
</code></pre>

<p>the basic operation of awk is to scan a sequence of input lines one after another, searching for lines that are matched by any of the patterns in the program. For each pattern that matches, the corresponding action is performed.</p></li>
<li><p>simple example</p>

<ul>
<li><p>NF, the number of fields. Print the number of fields and the first and last fields of each input line.</p>

<pre><code>  { print NF, $1, $NF }
</code></pre></li>
<li><p>NR, the number of lines read so far. Prefix each line of the file with its line number.</p>

<pre><code>  { print NR, $0 }
</code></pre></li>
<li><p>Putting text in the output.</p>

<pre><code>  { print "this is",NR,"line",$0 }
</code></pre></li>
<li><p>Fancier Output, use <code>printf</code> statement</p></li>
<li><p>Selection by comparision</p>

<pre><code>  $2 &gt;= 5
</code></pre></li>
<li><p>Selection by text content</p>

<pre><code>  $1 == "Susie"
</code></pre></li>
<li><p>Combinations of patterns. <code>&amp;&amp;</code>,<code>||</code>,<code>!</code>, which stand for AND, OR, NOT</p>

<pre><code>  $2 &gt;=4 || $3 &gt;= 20
</code></pre></li>
<li><p>BEGIN and END. The special pattern <code>BEGIN</code> matches before the first line of the first input file read, and <code>END</code> matches after the last line of the last file has been processed. The following example uses <code>BEGIN</code> to print a heading.</p>

<pre><code>  BEGIN { print "NAME  RATE  HOURS"; print "" }
  { print }
</code></pre>

<p>  注意，第一个<code>print ""</code> 输出一个空行</p></li>
<li><p>Exchange the first two fields of every line and then print the line</p>

<pre><code>  { temp = $1; $1 = $2; $2 = temp; print }
</code></pre></li>
<li><p>Print in reverse order the fields of every line</p>

<pre><code>  { for (i = NF; i &gt; 0; i = i - 1) printf("%s ", $i)
      printf("\n")
  }
</code></pre></li>
<li><p>Print the sums of the fields of every line</p>

<pre><code>  { sum = 0
      for (i = 1; i &lt;= NF; i = i + 1) sum = sum + $i
      print sum
  }
</code></pre></li>
<li><p>Print every line after replacing each field by its absolute value</p>

<pre><code>  { for (i = 1; i &lt;= NF; i = i + 1) if ($i &lt; 0) $i = -$i
      print
  }
</code></pre></li>
</ul>
</li>
<li><p>Computing with AWK</p>

<p>  In awk, user-created variables are <strong>not</strong> declared.</p>

<ul>
<li><p>Counting</p>

<pre><code>  $3 &gt; 15 { emp = emp + 1 }
  END   { print emp, "employees worked more than 15 hours" }
</code></pre>

<p>  Awk varibales used as numbers begin life with the value 0, so we didn&rsquo;t need to initialize emp.</p></li>
<li><p>String Concatenation</p>

<pre><code>  { names = names $1 " " }
  END { print names }
</code></pre>

<p>  collects all the employee names into a single string, by appending each name and a blank to the previous value in the variable names.</p></li>
</ul>
</li>
<li><p>Control-Flow Statements</p>

<ul>
<li><p>if-else statement</p>

<pre><code>  $2 &gt; 6 { n = n + 1; pay = pay + $2 * $3 }
  END    { if (n &gt; 0)
                  print n, "employees, total pay is", pay,
                              "average pay is", pay/n
          else
              print "no employees are paid more than $6/hour"
          }
</code></pre></li>
<li><p>While Statement</p></li>
<li>For Statement</li>
</ul>
</li>
<li><p>String-Matching Patterns</p>

<ul>
<li><code>[.]</code>matches a period and <code>^[^^]</code>matches any character except a caret at the beginning of a string</li>
</ul>
</li>
<li><p>String-Manipulation Functions</p>

<ul>
<li><code>gsub</code>

<ul>
<li>Search target for all of the longest, leftmost, nonoverlapping matching substrings it can find and replace them with replacement. The ‘g’ in gsub() stands for “global,” which means replace everywhere.</li>
<li><code>gsub("^=\"|\"$", "", $33)</code>  &mdash;&ndash;>  &ldquo;=1234567&rdquo; &mdash;&ndash;> 1234567</li>
</ul>
</li>
</ul>
</li>
<li><p>Built-in Variables That Control awk</p>

<ul>
<li><p>FS</p>

<ul>
<li>The input field separator.</li>
</ul>
</li>
<li><p>OFS</p>

<ul>
<li>The output field separator. It is output between the fields printed by a print statement. Its default value is &ldquo; &rdquo;, a string consisting of a single space.</li>
<li>对<code>print</code>有效，会被<code>printf</code>忽略</li>
</ul>
</li>
<li><p>RS</p>

<ul>
<li>The input record separator. Its default value is a string containing a single newline character, which means that an input record consists of a single line of text.</li>
<li>这个字段的用处是，可以手动指定行结束符，一般用不上，不过当在unix系统上处理windows生成的文件时，并且在某些字段中含有未转义的<code>\n</code>时。这时，指定<code>RS="\r\n"</code>后，你就会感谢上帝给你提供了RS这个设置</li>
</ul>
</li>
<li>ORS

<ul>
<li>The output record separator. It is output between the fields printed by a print statement. Its default value is &ldquo; &rdquo;, a string consisting of a single space.</li>
<li>注意，该变量只对<code>print</code>语句有效，<code>printf</code>语句会忽略这个变量的设置，<strong>必须显式指定行分隔符</strong>，否则所有的记录都在一行上！</li>
</ul>
</li>
<li>FPAT

<ul>
<li>gawk专有的</li>
<li>A regular expression (as a string) that tells gawk to create the fields based on text that matches the regular expression. Assigning a value to FPAT overrides the use of FS and FIELDWIDTHS for field splitting.</li>
<li>处理字段中含有<code>,</code>的csv文件的大杀器

<ul>
<li>比如这样的<code>Robbins,Arnold,"1234 A Pretty Street, NE",MyTown,MyState,12345-6789,USA</code></li>
<li>可以设置<code>FPAT = "([^,]+)|(\"[^\"]+\")"</code>来正确提取出相应的字段，否则若只用逗号分隔符的话，会提取出错</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>Built-in Variables That Convey Information</p>

<p>  The following is an alphabetical list of variables that awk sets automatically on certain occasions in order to provide information to your program.</p>

<ul>
<li>ARGC, ARGV

<ul>
<li>The command-line arguments available to awk programs are stored in an array called ARGV. ARGC is the number of command-line arguments present.</li>
</ul>
</li>
<li>ARGIND

<ul>
<li>gawk专有，在处理多个文件时很有用</li>
<li><p>The index in ARGV of the current file being processed. Every time gawk opens a new data file for processing, it sets ARGIND to the index in ARGV of the file name. When gawk is processing the input files, ‘FILENAME == ARGV[ARGIND]’ is always true.</p>

<pre><code>  awk -F, 'ARGIND==1{data[$1]=1} ARGIND==2{if(!($1 in data)) print $1}' dedao_mall_transaction_uniq.csv gongzhonghao_caifutong_uniq.csv &gt; in_caifutong_not_in_dedao.csv
</code></pre>

<p>  上面这个例子可用于比较两个文件的差异</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Array</p>

<ul>
<li><p><a href="https://www.gnu.org/software/gawk/manual/gawk.html#Array-Basics">https://www.gnu.org/software/gawk/manual/gawk.html#Array-Basics</a></p>

<pre><code>  awk -F, '{ data[$1]["amount"] += $5; data[$1]["product_price*amount"] += $3*$5; data[$1]["refund"] += $6; data[$1]["pay_price*amount"] += $4*$5; data[$1]["discount_price"] += ($3-$4)*$5;}\
  END{for (d in data) printf("%s,%d,%.2f,%.2f,%.2f,%.2f\n", d, data[d]["amount"], data[d]["product_price*amount"], data[d]["pay_price*amount"], data[d]["discount_price"], data[d]["refund"])}' \
  tt_new.csv | awk -F, 'BEGIN{printf("%s,%s,%s,%s,%s,%s\n", "sku", "amount", "product_price*amount", "pay_price*amount", "discount_price", "refund")} {print $0}' &gt; summary_by_sku.csv

 上面的例子用到了gawk扩展的多维array特性，不适用于unix下默认的awk
</code></pre></li>
</ul>
</li>
</ul>


<h3>避坑指南</h3>

<p>这几天用awk写了几个处理数据的小程序，顺便总结下遇到的坑：</p>

<ul>
<li>由于操作系统平台不同引起的问题

<ul>
<li>换行符

<ul>
<li>win平台为<code>\r\n</code>，*nix平台为<code>\n</code>。因此在比较两个文件时，切记先把换行符转换为一致再比较，否则会发生“明明看起来是一样的，但为啥不一样呢？”的令人困惑的情况。</li>
</ul>
</li>
<li>文件编码问题

<ul>
<li>*nix系统下一般使用<code>utf-8</code>编码，win平台中文环境一般为gb18030编码。更需要注意的是中国人民的好朋友Excel，在编辑完csv文件再保存后，会把文件编码强制更改为gb18030，即使原来的文件编码是utf-8.</li>
</ul>
</li>
</ul>
</li>
</ul>


<h3>参考</h3>

<ul>
<li>The GNU Awk User’s Guide

<ul>
<li><a href="https://www.gnu.org/software/gawk/manual/gawk.html#Index">https://www.gnu.org/software/gawk/manual/gawk.html</a></li>
</ul>
</li>
<li>The AWK Programming Language</li>
</ul>


		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2017/02/22/process-data-using-awk//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2017/01/14/thrift-server-error-caused-by-aliyun-health-check/">
		
			Thrift Server Error Caused by Aliyun Health Check</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2017-01-14T21:58:00+08:00" pubdate data-updated="true">Jan 14<span>th</span>, 2017</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<p>近期遇到一个thrift server方面的问题，记录一下。</p>

<h3>Background</h3>

<p>server做的事情其实很简单，就是一个图片上传服务，别人把图片传过来，服务器上传到阿里云的云上，再返回一个图片地址。</p>

<p>问题暴露出来的现象是：这个服务每隔一段时间就会“挂掉”，重启服务后会好那么一段时间然后又会“挂掉”。客户端调用返回<code>TSocket: Could read 4 bytes from ....</code>，但去线上ps会发现，server进程其实是在的，
也就是说服务器其实只是不响应了，并没有真正挂掉。</p>

<h3>First guess</h3>

<p>分析后台日志发现，大量重复的报错信息<code>Connection reset by peer</code>，以及偶尔的错误信息<code>too many open files</code>（其实，这个偶尔也只是猜测，因为并没有完整的确认过），当时看到这个日志后，就猜测
原因是：请求太多，导致该程序打开的文件描述符超过限制，从而拒绝服务。由于是线上服务，出现问题时为了及时恢复服务，当时就重启了服务，因此也并没有验证这个猜测。但看了下操作系统对单个程序
打开文件数的限制:</p>

<pre><code>$ ulimit -n 
65535
</code></pre>

<p>基于too many open files这个错误加上这个thrift server使用的ThreadPoolServer类型，google了一番，找到几个类似问题的帖子：</p>

<ul>
<li><a href="http://blog.csdn.net/heavendai/article/details/8614941">http://blog.csdn.net/heavendai/article/details/8614941</a></li>
<li><a href="http://web.archive.org/web/20110103083546/http://blog.rushcj.com/2010/12/20/thrift-close-wait/">http://web.archive.org/web/20110103083546/http://blog.rushcj.com/2010/12/20/thrift-close-wait/</a></li>
<li><a href="http://blog.csdn.net/hwz119/article/details/1611182">http://blog.csdn.net/hwz119/article/details/1611182</a></li>
</ul>


<p>里面讲到，ThreadPoolServer来说，它使用的是定长线程池来服务的，当并发太多时使得现存的线程数无法满足要求时，就会出现很多<code>CLOSE_WAIT</code>状态的连接，最终会
把当前程序的文件描述符占满，从而出现<code>too many open files</code>的错误。正好这个服务用的线程是默认的，只有10个，当时就认为问题就在这里了。</p>

<h3>Second guess</h3>

<p>然后第二天又问了下服务调用方，其实这个服务的使用频率很低，只有在用户更改头像的时候才会调一下，按理说不会有太多并发量，所以这样看来，上面的猜测就不成立了。然后去线上看了下，该服务一共部署了两台机器，
发现其中一台机器上的服务又“挂了”，抓住这个好机会，看了下这个服务的socket连接情况：</p>

<pre><code># 先找到程序的进程id
$ ps aux | grep 'xxx'
# 然后再用lsof看
$ lsof -i -P | grep 28719
python  28719  www    4u  IPv4 261027973      0t0  TCP *:9455 (LISTEN)
python  28719  www    5u  IPv4 261328458      0t0  TCP 10.171.20.131:9455-&gt;100.109.225.0:45587 (ESTABLISHED)
python  28719  www    6u  IPv4 261327693      0t0  TCP 10.171.20.131:9455-&gt;100.109.221.128:23814 (ESTABLISHED)
python  28719  www    7u  IPv4 261429153      0t0  TCP 10.171.20.131:9455-&gt;100.109.224.0:17384 (ESTABLISHED)
python  28719  www    8u  IPv4 261717598      0t0  TCP 10.171.20.131:9455-&gt;100.109.225.0:23881 (ESTABLISHED)
python  28719  www    9u  IPv4 261429722      0t0  TCP 10.171.20.131:9455-&gt;100.109.225.128:19752 (ESTABLISHED)
python  28719  www   10u  IPv4 261470638      0t0  TCP 10.171.20.131:9455-&gt;100.109.220.128:14370 (ESTABLISHED)
python  28719  www   11u  IPv4 261456259      0t0  TCP 10.171.20.131:9455-&gt;100.109.224.128:24267 (ESTABLISHED)
python  28719  www   12u  IPv4 261714765      0t0  TCP 10.171.20.131:9455-&gt;100.109.220.0:8860 (ESTABLISHED)
python  28719  www   13u  IPv4 261470701      0t0  TCP 10.171.20.131:9455-&gt;100.109.221.0:42186 (ESTABLISHED)
python  28719  www   14u  IPv4 261717599      0t0  TCP 10.171.20.131:9455-&gt;100.109.224.0:3487 (ESTABLISHED)
python  28719  www   98u  IPv4 261718019      0t0  TCP 10.171.20.131:9455-&gt;100.109.220.0:37454 (ESTABLISHED)
python  28719  www  827u  IPv4 261722045      0t0  TCP 10.171.20.131:9455-&gt;10.44.155.227:24038 (CLOSE_WAIT)
python  28719  www  914u  IPv4 261722497      0t0  TCP 10.171.20.131:9455-&gt;10.172.224.17:35876 (CLOSE_WAIT)
python  28719  www 1309u  IPv4 261724582      0t0  TCP 10.171.20.131:9455-&gt;10.172.142.166:52953 (CLOSE_WAIT)
python  28719  www 1329u  IPv4 261724675      0t0  TCP 10.171.20.131:9455-&gt;10.44.155.227:52921 (CLOSE_WAIT)
python  28719  www 1672u  IPv4 261726365      0t0  TCP 10.171.20.131:9455-&gt;10.44.191.118:7070 (CLOSE_WAIT)
python  28719  www 1694u  IPv4 261726531      0t0  TCP 10.171.20.131:9455-&gt;10.170.210.248:39802 (CLOSE_WAIT)
</code></pre>

<p>可以看到<code>CLOSE_WAIT</code>状态的连接并不多，但此时这台机器上部署的服务已经不能用了。同时又去现在还可用的机器上看了下，发现只有状态为<code>ESTABLISHED</code>的连接，并没有状态为<code>CLOSE_WAIT</code>的连接，
同时发现日志在不停的报错：<code>Connection reset by peer</code>。但并没人反馈服务不可用啊，看了下图片上传还是可用的，正百思不得其解中，运维哥哥说，这不会是阿里云的健康检查导致的吧！于是，
暂停了一下健康检查，果然日志的报错停止了。</p>

<p>然后我的猜测又变成了：由于阿里云的持续不断的健康检查（2秒一次）把服务检查挂了。。显然，运维是不会认可这个猜测的，他们说报这个错是正常的，别的服务也有这个问题，只要不理会它就行了。
说实话，光看这个，确实无法断定服务挂是由于健康检查的原因。况且我也查了下阿里云所谓的健康检查，找到了如下官方资料：</p>

<ul>
<li><a href="https://help.aliyun.com/knowledge_list/39451.html?spm=5176.7739464.6.753.FE0164">https://help.aliyun.com/knowledge_list/39451.html?spm=5176.7739464.6.753.FE0164</a></li>
<li><a href="https://help.aliyun.com/knowledge_detail/39455.html?spm=5176.7839451.2.4.KKMkQd">https://help.aliyun.com/knowledge_detail/39455.html?spm=5176.7839451.2.4.KKMkQd</a></li>
<li><a href="https://help.aliyun.com/knowledge_detail/39464.html?spm=5176.7839451.2.13.KKMkQd">https://help.aliyun.com/knowledge_detail/39464.html?spm=5176.7839451.2.13.KKMkQd</a></li>
</ul>


<p>看来阿里云官方确认认为这个错误是正常的。</p>

<p>第二天，又去线上看了下，发现某一台机器上的服务又“挂了”，看了下这次的“车祸现场”，注意到了一点上次没有注意的细节：</p>

<ul>
<li>有11个状态为<code>ESTABLISHED</code>的连接</li>
<li>这个11个状态为<code>ESTABLISHED</code>的连接的另一边都是来自阿里云健康检查的网段ip</li>
<li>此时，如果调用该服务会返回错误，而且会增加一条状态为<code>CLOSE_WAIT</code>的socket连接</li>
<li>对于目前可用的机器上的服务，没有状态为<code>CLOSE_WAIT</code>的连接，但有几个状态为<code>ESTABLISHED</code>的连接，而且尽管没有人调用它，状态为<code>ESTABLISHED</code>的连接数在慢慢增加。</li>
</ul>


<p>由此，可以基本断定，罪魁祸首就是阿里云的健康检查了。健康检查把当前服务的可用连接数（10个线程只能同时服务10个连接）用完了，并且没有释放，再进来的连接只能wait了。那么现在唯一的问题
就是：Why？阿里云的健康检查为什么会对thrift服务造成这样的结果？我还没有找到原因。从阿里云的官方文档中看到，所谓的TCP健康检查，是对指定ip的指定端口进行了三次握手然后发送了RST断开了
连接，没有看到他们说会造成连接一直不释放的情况。</p>

<p>google到一篇阿里云上部署thrift server出问题的文章，里面也提到了健康检查：</p>

<ul>
<li><a href="http://www.concurrent.work/one-java-thrift-case-caused-by-default-parameters/">http://www.concurrent.work/one-java-thrift-case-caused-by-default-parameters/</a></li>
</ul>


<h3>反思</h3>

<ul>
<li>不要急于下结论。先把日志完整分析下，服务的使用场景也要了解下，再下结论，而不要看到一点问题就瞎猜。</li>
<li>需要了解下网络方面的基础知识了。</li>
</ul>


		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2017/01/14/thrift-server-error-caused-by-aliyun-health-check//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2016/09/13/first-glance-at-django-admin/">
		
			First Glance at Django Admin</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2016-09-13T17:27:00+08:00" pubdate data-updated="true">Sep 13<span>th</span>, 2016</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<p>主要是一些定制的问题，其实django admin已经集成的非常好了，该有的都有了，一般开箱即用就行了。</p>

<p>如果你对Django Admin不熟悉的话，<a href="http://dokelung-blog.logdown.com/posts/220832-django-notes-6-manage-your-system-admin">这里</a>有一篇很好的介绍。</p>

<h3>dependent select fields</h3>

<p>其实就是子field的可选项是依赖它的父field的，这个需求在admin中没有找到配置方法，找到一个插件<a href="https://github.com/digi604/django-smart-selects"><code>django-smart-selects</code></a></p>

<h3>model field options</h3>

<ul>
<li><p>blank=True，实际控制的form的validation，允许表单中该字段为空</p></li>
<li><p>null=True，控制的DB中字段的属性，null或者not null</p></li>
</ul>


<h3>控制某条记录的显示</h3>

<p>需要在model的定义中加入：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">def</span> <span class="nf">__unicode__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span><span class='line'>  <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span>
</span></code></pre></td></tr></table></div></figure>


<p>否则，记录显示出来的是Python object</p>

<h3>在view中显示的model名称的自定义</h3>

<p>这个名称默认就是显示的是在代码中定义的model的名称，可以用以下代码来自定义：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">Meta</span><span class="p">:</span>
</span><span class='line'>  <span class="n">verbose_name</span> <span class="o">=</span> <span class="s">u&#39;商品子类&#39;</span>
</span><span class='line'>  <span class="n">verbose_name_plural</span> <span class="o">=</span> <span class="s">u&#39;商品子类&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>自定义app名称</h3>

<p>参考<a href="http://stackoverflow.com/questions/612372/can-you-give-a-django-app-a-verbose-name-for-use-throughout-the-admin">这里</a></p>

<h3>多个字段作为一个唯一键</h3>

<p>需要在该表对应的model类的Meta类中增加<code>unique_together</code>定义：</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">Meta</span><span class="p">:</span>
</span><span class='line'>  <span class="n">unique_together</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;name&#39;</span><span class="p">,</span> <span class="s">&#39;parent_category&#39;</span><span class="p">,</span> <span class="s">&#39;sub_category&#39;</span><span class="p">)</span>
</span><span class='line'>  <span class="n">verbose_name</span> <span class="o">=</span> <span class="s">u&#39;商品&#39;</span>
</span><span class='line'>  <span class="n">verbose_name_plural</span> <span class="o">=</span> <span class="s">u&#39;商品&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<h3>对显示界面的定制</h3>

<p>比如，控制要显示的字段、哪几个字段是可以点击的、显示搜索框、分页等，这些都是可以配置的，不用自己来实现，非常方便。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">ProductAdmin</span><span class="p">(</span><span class="n">admin</span><span class="o">.</span><span class="n">ModelAdmin</span><span class="p">):</span>
</span><span class='line'>    <span class="n">list_display</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;name&#39;</span><span class="p">,</span> <span class="s">&#39;sku&#39;</span><span class="p">,</span> <span class="s">&#39;barcode&#39;</span><span class="p">,</span> <span class="s">&#39;price&#39;</span><span class="p">,</span> <span class="s">&#39;description&#39;</span><span class="p">,</span> <span class="s">&#39;create_time&#39;</span><span class="p">,</span> <span class="s">&#39;update_time&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">list_display_links</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;name&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">exclude</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;sku&#39;</span><span class="p">,)</span>
</span><span class='line'>    <span class="n">search_fields</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;name&#39;</span><span class="p">,)</span>
</span><span class='line'>    <span class="n">list_per_page</span> <span class="o">=</span> <span class="mi">100</span>
</span><span class='line'>    <span class="n">ordering</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">empty_value_display</span> <span class="o">=</span> <span class="s">&#39;-&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>参考：</p>

<ul>
<li><a href="https://brobin.me/blog/2015/03/customizing-the-django-admin/">https://brobin.me/blog/2015/03/customizing-the-django-admin/</a></li>
<li><a href="https://www.webforefront.com/django/setupdjangomodelsindjangoadmin.html#prettyPhoto">https://www.webforefront.com/django/setupdjangomodelsindjangoadmin.html#prettyPhoto</a>  这篇讲的非常详尽，但其实都在官方文档里了，但有时候懒得一个一个去找了。</li>
</ul>


<h3>自定义方法（ModelAdmin methods）</h3>

<p>Django的admin提供了一系列的方法，支持你通过重写这些方法来定制它的默认行为，比如<code>save_model</code>方法可以让你自定义入库的操作，加入一些自己的逻辑。它提供了非常多的方法，具体可以看文档，我目前只用到了一个<code>save_model</code>方法。</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="k">class</span> <span class="nc">ProductAdmin</span><span class="p">(</span><span class="n">admin</span><span class="o">.</span><span class="n">ModelAdmin</span><span class="p">):</span>
</span><span class='line'>    <span class="n">list_display</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;name&#39;</span><span class="p">,</span> <span class="s">&#39;sku&#39;</span><span class="p">,</span> <span class="s">&#39;barcode&#39;</span><span class="p">,</span> <span class="s">&#39;price&#39;</span><span class="p">,</span> <span class="s">&#39;description&#39;</span><span class="p">,</span> <span class="s">&#39;create_time&#39;</span><span class="p">,</span> <span class="s">&#39;update_time&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">list_display_links</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;id&#39;</span><span class="p">,</span> <span class="s">&#39;name&#39;</span><span class="p">)</span>
</span><span class='line'>    <span class="n">exclude</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;sku&#39;</span><span class="p">,)</span>
</span><span class='line'>    <span class="n">search_fields</span> <span class="o">=</span> <span class="p">(</span><span class="s">&#39;name&#39;</span><span class="p">,)</span>
</span><span class='line'>    <span class="n">list_per_page</span> <span class="o">=</span> <span class="mi">100</span>
</span><span class='line'>    <span class="n">ordering</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;id&#39;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">empty_value_display</span> <span class="o">=</span> <span class="s">&#39;-&#39;</span>
</span><span class='line'>
</span><span class='line'>    <span class="k">def</span> <span class="nf">save_model</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">request</span><span class="p">,</span> <span class="n">obj</span><span class="p">,</span> <span class="n">form</span><span class="p">,</span> <span class="n">change</span><span class="p">):</span>
</span><span class='line'>        <span class="k">if</span> <span class="ow">not</span> <span class="n">change</span><span class="p">:</span>         <span class="c"># Add</span>
</span><span class='line'>            <span class="n">obj</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>         <span class="c">#  save in order to get the auto increment id</span>
</span><span class='line'>            <span class="n">generate_sku</span><span class="p">(</span><span class="n">obj</span><span class="p">)</span>
</span><span class='line'>            <span class="n">obj</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>         <span class="c">#  save generated sku</span>
</span><span class='line'>        <span class="k">else</span><span class="p">:</span>                  <span class="c"># Update</span>
</span><span class='line'><span class="c">#            generate_sku(obj) # sku should not be changed once the record is inserted, even if all the other fields have changed</span>
</span><span class='line'>            <span class="n">obj</span><span class="o">.</span><span class="n">save</span><span class="p">()</span>
</span><span class='line'>
</span><span class='line'><span class="k">def</span> <span class="nf">generate_sku</span><span class="p">(</span><span class="n">obj</span><span class="p">):</span>
</span><span class='line'>    <span class="nb">id</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">id</span>
</span><span class='line'>    <span class="n">parent_category</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">parent_category</span><span class="o">.</span><span class="n">code</span>
</span><span class='line'>    <span class="n">sub_category</span> <span class="o">=</span> <span class="n">obj</span><span class="o">.</span><span class="n">sub_category</span><span class="o">.</span><span class="n">code</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">sku_parts</span> <span class="o">=</span> <span class="p">[</span><span class="s">&#39;XLJ&#39;</span><span class="p">]</span>
</span><span class='line'>    <span class="n">sku_parts</span><span class="o">.</span><span class="n">extend</span><span class="p">([</span><span class="n">parent_category</span><span class="p">,</span> <span class="n">sub_category</span><span class="p">,</span> <span class="s">&#39;X&#39;</span><span class="p">])</span>
</span><span class='line'>    <span class="n">today</span> <span class="o">=</span> <span class="n">date</span><span class="o">.</span><span class="n">today</span><span class="p">()</span>
</span><span class='line'>    <span class="n">sku_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">today</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s">&#39;%y%m</span><span class="si">%d</span><span class="s">&#39;</span><span class="p">))</span>
</span><span class='line'>    <span class="n">seq_id</span> <span class="o">=</span> <span class="s">&#39;</span><span class="si">%06d</span><span class="s">&#39;</span> <span class="o">%</span> <span class="nb">id</span>
</span><span class='line'>    <span class="n">sku_parts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">seq_id</span><span class="p">)</span>
</span><span class='line'>
</span><span class='line'>    <span class="n">sku</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s">r&#39;[^a-zA-Z0-9]&#39;</span><span class="p">,</span> <span class="s">&#39;&#39;</span><span class="p">,</span> <span class="s">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">sku_parts</span><span class="p">))</span>
</span><span class='line'>    <span class="n">obj</span><span class="o">.</span><span class="n">sku</span> <span class="o">=</span> <span class="n">sku</span>
</span></code></pre></td></tr></table></div></figure>


<p>参考：</p>

<ul>
<li><a href="https://docs.djangoproject.com/en/dev/ref/contrib/admin/#modeladmin-methods">https://docs.djangoproject.com/en/dev/ref/contrib/admin/#modeladmin-methods</a></li>
</ul>


		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2016/09/13/first-glance-at-django-admin//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2016/08/29/csapp-concurrent-programming/">
		
			Csapp Concurrent Programming</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2016-08-29T14:12:00+08:00" pubdate data-updated="true">Aug 29<span>th</span>, 2016</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<p>Applications that use application-level concurrency are known as concurrent programs. Modern operating systems provide three basic approaches for building concurrent programs:</p>

<ul>
<li><p>Processes. With this approach, each logical control flow is a process that is scheduled and maintained by the kernel. Since processes have separate virtual address spaces, flows that want to communicate with each other must use some kind of explicit interprocess communication (IPC) mechanism.</p></li>
<li><p>I/O multiplexing.This is a form of concurrent programming where <strong>applications explicitly schedule their own logical flows in the context of a single process</strong>. Logical flows are modeled as state machines that the main program explicitly transitions from state to state as a result of data arriving on file descriptors. Since the program is a single process, all flows share the same address space.</p></li>
<li><p>Threads. Threads are logical flows that run in the context of a single process and are scheduled by the kernel. You can think of threads as a hybrid of the other two approaches, scheduled by the kernel like process flows, and sharing the same virtual address space like I/O multiplexing flows.</p></li>
</ul>


<h3>IO之殇</h3>

<p>Access to the filesystem or the network are really long operations from the perspective of the CPU. See the numbers from Jeffrey Dean’s talk Stanford CS295 class lecture, Spring, 2007.</p>

<pre><code>Operation     Latency
L1 cache reference     0.5 ns
Branch mispredict     5 ns
L2 cache reference     7 ns
Mutex lock/unlock     25 ns
Main memory reference     100 ns
Compress 1K bytes with Zippy     3,000 ns
Send 2K bytes over 1 Gbps network     20,000 ns
Read 1 MB sequentially from memory     250,000 ns
Round trip within same datacenter     500,000 ns
Disk seek     10,000,000 ns
Read 1 MB sequentially from disk     20,000,000 ns
Send packet CA-&gt;Netherlands-&gt;CA     150,000,000 ns
</code></pre>

<p>Blocking I/Os (or synchronous I/Os) will tie up the system resources as the waiting processes/threads cannot be used for something else. And from the CPU perspective, any I/O which is not done from/to memory takes ages. Fortunately the system itself is not stuck while I/Os are happening. The OS is going to preempt (i.e. interrupt) the process waiting for an I/O, allowing the CPU to be used by another process. But <strong>this costs another context switch and meanwhile I/O intensive applications will spend most of their time… waiting!</strong></p>

<p>对于multi-process/threading来说</p>

<p>So, the more processes there are, the more they will compete for the CPU. <strong>The more I/Os the application is doing, the more context switches there are, amplified by the number of process/threads the application is made of.</strong> At some point, no matter how good the operating system is, it is going to become overwhelmed. It will spend most of its time switching contexts and have many processes/threads waiting either for I/O or to acquire the CPU. This basically means that <strong>in such a model, the scalability is not at all linear to the number of processes/threads up to the CPU limit. The capacity gain of adding a process/thread significantly decreases with the number of active processes/threads.</strong></p>

<h3>Concurrent Programming with Processes</h3>

<p>Pros and Cons of Processes</p>

<p>Processes have a clean model for sharing state information between parents and children: file tables are shared and user address spaces are not. Having separate address spaces for processes is both an advantage and a disadvantage. It is im- possible for one process to accidentally overwrite the virtual memory of another process, which eliminates a lot of confusing failures—an obvious advantage.</p>

<p>On the other hand, separate address spaces make it more difficult for pro- cesses to share state information. To share information, they must use explicit IPC (interprocess communications) mechanisms. (See Aside.) Another disadvan- tage of process-based designs is that they tend to be slower because the overhead for process control and IPC is high.</p>

<h3>Concurrent Programming with I/O Multiplexing</h3>

<p>The select function manipulates sets of type <code>fd_set</code>, which are known as descriptor sets. Logically, we think of a descriptor set as a bit vector of size n: bn−1,&hellip;,b1,b0</p>

<p>Each bit bk corresponds to descriptor k. Descriptor k is a member of the descriptor set if and only if bk = 1.</p>

<p>the select function takes two inputs: a descriptor set (fdset) called the read set, and the cardinality (n) of the read set (actually the maximum cardinality of any descriptor set). <strong>The select function blocks until at least one descriptor in the read set is ready for reading. A descriptor k is ready for reading if and only if a request to read 1 byte from that descriptor would not block.</strong>select函数也是会阻塞的。</p>

<p>Question: IO多路复用是如何实现并发的效果的？</p>

<p>本质上是Event Driven Model来实现并发的，I/O Multiplexing只是必不可少的一环，有了它，使用Event Driven Model才成为可能。</p>

<p>我是这样理解的：在一个事件循环（event loop）中，不断的调用select来返回当前可读、可写的descriptor，然后做相应的处理，一直循环往复。在这个过程中的一个关键是，只有select操作是阻塞的，一旦它有返回，后面的操作就一定不是阻塞的，所以就不会有无谓的时间浪费在等待读和等待写上面。如果CPU的执行速度够快，那么从一个使用者的角度来看的话，就会看到并发的效果（而实质上这些“并发”的连接是按顺序被处理的）。这个道理现在看来，跟单核CPU上的多进程、多线程是一个道理（CPU-time multiplexing）。感觉实现并发效果的关键是：select的这个过程要足够快，然后对select返回的descriptor的处理也要快，否则就不会有并发的效果了。</p>

<h4>Pros and Cons of I/O Multiplexing</h4>

<ul>
<li><p>One advantage is that event-driven designs give programmers more control over the behavior of their programs than process-based designs. For example, we can imagine writing an event-driven concurrent server that gives preferred service to some clients, which would be difficult for a concurrent server based on processes. 程序员对自己的程序有更多的控制，比如优先提供某个服务，而不是像基于进程的并发那样，完全交给操作系统来决定。</p></li>
<li><p>Another advantage is that an event-driven server based on I/O multiplexing runs in the context of a single process, and thus every logical flow has access to the entire address space of the process.This makes it easy to share data between flows. A related advantage of running as a single process is that you can debug your concurrent server as you would any sequential program, using a familiar debugging tool such as gdb. Finally, event-driven designs are often significantly more efficient than process-based designs because they do not require a process context switch to schedule a new flow. 由于是单进程，所以共享更方便；debug难度也比多进程要低；资源消耗也比多进程低（因为没有context switch）</p></li>
<li><p>A significant disadvantage of event-driven designs is coding complexity. 缺点就是代码的复杂度上来了。</p></li>
<li><p>Another significant disadvantage of event-based designs is that they cannot fully utilize multi-core processors. 还有一个缺点是不能利用多核</p></li>
</ul>


<h4>Event Driven Programming又是什么呢？</h4>

<p>常常看到event driven和I/O Multiplexing这两个概念在一起。我是这样理解的，通过I/O Multiplexing可以提供event driven programming中的事件。</p>

<p>In an event model, everything runs in one process, one thread. Instead of spawning a new process/thread for each connection request, a event is emitted and the appropriate callback for that event is invoked. Once an event is treated, the process is ready to treat another event.</p>

<p>Such a model is particularly interesting if most of the activities can be turned into events. This becomes a really good concurrency and high-performance model when any I/Os (not just network I/O as is the most common in existing frameworks) are events. It is based on event patterns such as the Reactor or the Proactor which are patterns for Concurrent, Parallel, and Distributed Systems; documents from Douglas C. Schmidt. This event-driven concurrency model is superior to the traditional multithreaded/multi-process one: the memory footprint is drastically reduced, the CPU is better used and more clients can be served concurrently out of a single machine.</p>

<h4>The Event Loop</h4>

<p>To some extent, one can consider the event-driven approach being very similar to cooperative multitasking but at the application level. Event-driven applications are themselves multiplexing CPU time between clients.</p>

<p>There is obviously a risk with this; the same that with cooperative multitasking in fact. A risk which explains why at the OS level, preemptive multitasking is used. <strong>If the process at some point can block for one client, then it will block all the other clients.</strong> For example, in cooperative multitasking a non-responding process would make the system hang (Remember Windows before Windows 95 or Mac OS before Mac OS X ? )</p>

<p>In event-driven model, all the events are treated by a gigantic loop know as the event-loop. The event-loop is going to get from a queue the next event to process and will dispatch it the corresponding handler. Anyone blocking the event-loop will prevent the other events from being processed. So in Node (and in all event-driven framework) the golden rule is <strong>“DO NOT BLOCK THE EVENT LOOP”.</strong> Everything has to be non-blocking. And Node is particularly good at this because all the API it exposes is non-blocking (with the exception of some file system operations which come in two flavors: asynchronous and synchronous).</p>

<h4>参考</h4>

<ul>
<li><a href="http://www.baloo.io/blog/2013/11/30/node-event-driven-programming/">Node-Event-driven programming</a></li>
</ul>


<h3>Concurrent Programming with Threads</h3>

<p>A thread is a logical flow that runs in the context of a process. modern systems also allow us to write programs that have multiple threads running concurrently in a single process. The threads are scheduled automatically by the kernel. <strong>Each thread has its own thread context, including a unique integer thread ID (TID), stack, stack pointer, program counter, general-purpose registers, and condition codes.</strong> All threads running in a process share the entire virtual address space of that process.</p>

<h4>Thread Execution Model</h4>

<p><strong>Each process begins life as a single thread called the main thread.</strong> At some point, the main thread creates a peer thread, and from this point in time the two threads run concurrently. Eventually, control passes to the peer thread via a context switch, because the main thread executes a slow system call such as read or sleep, or because it is interrupted by the system’s interval timer. The peer thread executes for a while before control passes back to the main thread, and so on.</p>

<p>Thread execution differs from processes in some important ways. Because a thread context is much smaller than a process context, a thread context switch is faster than a process context switch(由于thread context要比process context要小，所以上下文切换要比进程快). Another difference is that threads, unlike processes, are not organized in a rigid parent-child hierarchy. The threads associated with a process form a pool of peers, independent of which threads were created by which other threads. The main thread is distinguished from other threads only in the sense that it is always the first thread to run in the process. The main impact of this notion of a pool of peers is that a thread can kill any of its peers, or wait for any of its peers to terminate. Further, each peer can read and write the same shared data.(进程内的线程之间没有父子的继承关系，都是平等的，一个线程可以kill或者wait其它任何线程，主线程跟其它线程的唯一区别是它总是一个第一个被创建的)</p>

<h4>Terminating Threads</h4>

<p>A thread terminates in one of the following ways:</p>

<ul>
<li><p>The thread terminates implicitly when its top-level thread routine returns. 上层的thread返回退出了（看这的意思感觉又是有层级关系了，主线程退出了，由它发起的其它线程也会terminates implicitly</p></li>
<li><p>The thread terminates explicitly by calling the &ldquo;pthread exit&rdquo; function. If the main thread calls &ldquo;pthread exit&rdquo;, it waits for all other peer threads to terminate, and then terminates the main thread and the entire process with a return value of <code>thread_return</code>.</p></li>
<li><p>Some peer thread calls the Unix exit function, which terminates the process and all threads associated with the process. 通过结束整个进程</p></li>
<li><p>Another peer thread terminates the current thread by calling the &ldquo;pthread cancel&rdquo; function with the ID of the current thread. 被其它线程kill</p></li>
</ul>


<h4>Detaching Threads</h4>

<p>At any point in time, a thread is joinable or detached. A joinable thread can be reaped and killed by other threads. Its memory resources (such as the stack) are not freed until it is reaped by another thread. In contrast, a detached thread cannot be reaped or killed by other threads. Its memory resources are freed automatically by the system when it terminates. detached状态的thread在退出后会被操作系统自动回收。</p>

<p>By default, threads are created joinable. In order to avoid memory leaks, each joinable thread should either be explicitly reaped by another thread, or detached by a call to the &ldquo;pthread detach&rdquo; function. 线程默认都是joinable的</p>

<h4>Shared Variables in Threaded Programs</h4>

<p>From a programmer’s perspective, one of the attractive aspects of threads is the ease with which multiple threads can share the same program variables. However, this sharing can be tricky. In order to write correctly threaded programs, <strong>we must have a clear understanding of what we mean by sharing and how it works.</strong></p>

<p>Threads Memory Model</p>

<p>A pool of concurrent threads runs in the context of a process. Each thread has its own separate thread context, which includes a thread ID, stack, stack pointer, program counter, condition codes, and general-purpose register values. Each thread shares the rest of the process context with the other threads. <strong>This includes the entire user virtual address space, which consists of read-only text (code), read/write data, the heap, and any shared library code and data areas. The threads also share the same set of open files.</strong></p>

<p>In an operational sense, <strong>it is impossible for one thread to read or write the register values of another thread.</strong> On the other hand, <strong>any thread can access any location in the shared virtual memory.</strong> If some thread modifies a memory location, then every other thread will eventually see the change if it reads that location. Thus, registers are never shared, whereas virtual memory is always shared.</p>

<h4>Synchronizing Threads with Semaphores</h4>

<p>Shared variables can be convenient, but they introduce the possibility of nasty <strong>synchronization errors</strong></p>

<p>Semaphores</p>

<p>Semaphores provide a convenient way to ensure mutually exclusive access to shared variables. The basic idea is to associate a semaphore s, initially 1, with each shared variable (or related set of shared variables) and then surround the corresponding critical section with P (s) and V (s) operations.</p>

<ul>
<li><p>P (s): If s is nonzero, then P decrements s and returns immediately. If s is zero, then suspend the thread until s becomes nonzero and the process is restarted by a V operation. After restarting, the P operation decrements s and returns control to the caller.</p></li>
<li><p>V (s): The V operation increments s by 1. If there are any threads blocked at a P operation waiting for s to become nonzero, then the V operation restarts exactly one of these threads, which then completes its P operation by decrementing s.</p></li>
</ul>


<p>The test and decrement operations in P occur indivisibly, in the sense that once the semaphore s becomes nonzero, the decrement of s occurs without in- terruption. The increment operation in V also occurs indivisibly, in that it loads, increments, and stores the semaphore without interruption.  注意，关键是P或者V操作都是原子操作，不可分割，这是能够实现锁的关键。</p>

<p>The definitions of P and V ensure that a running program can never enter a state where a properly initialized semaphore has a negative value. This property, known as the semaphore invariant, provides a powerful tool for controlling the trajectories of concurrent programs</p>

<p>Synchronizing Threads with Semaphores</p>

<p>A semaphore that is used in this way to protect shared variables is called a binary semaphore because its value is always 0 or 1. <strong>Binary semaphores whose purpose is to provide mutual exclusion are often called mutexes.</strong> Performing a P operation on a mutex is called locking the mutex. Similarly, <strong>performing the V operation is called unlocking the mutex. A thread that has locked but not yet unlocked a mutex is said to be holding the mutex. </strong></p>

<p>Using Semaphores to Schedule Shared Resources</p>

<p>Another important use of semaphores, besides providing mutual exclusion, is to <strong>schedule accesses to shared resources.</strong> In this scenario, a thread uses a semaphore operation to notify another thread that some condition in the program state has become true. Two classical and useful examples are the producer-consumer and readers-writers problems.</p>

<p>Producer-Consumer Problem</p>

<p>A producer and consumer thread share a bounded buffer with n slots. The producer thread repeatedly produces new items and inserts them in the buffer. The consumer thread repeat- edly removes items from the buffer and then consumes (uses) them. Variants with multiple producers and consumers are also possible.</p>

<p>Since inserting and removing items involves updating shared variables, we must guarantee mutually exclusive access to the buffer. But guaranteeing mutual exclusion is not sufficient. We also need to schedule accesses to the buffer. If the buffer is full (there are no empty slots), then the producer must wait until a slot becomes available. Similarly, if the buffer is empty (there are no available items), then the consumer must wait until an item becomes available. 不仅要保证对共享变量的独享读写，而且还有保证先后顺序，必须要先生产再消费。</p>

<h4>Other Concurrency Issues</h4>

<p>You probably noticed that life got much more complicated once we were asked to synchronize accesses to shared data. Synchronization is a fundamentally difficult problem that raises issues that simply do not arise in ordinary sequential programs.</p>

<p>Thread Safety</p>

<p>A function is said to be thread-safe if and only if it will always produce correct results when called repeatedly from multiple concurrent threads. If a function is not thread-safe, then we say it is thread-unsafe.</p>

<p>四类线程非安全的函数：</p>

<ul>
<li><p>Functions that do not protect shared variables. This class of thread-unsafe function is relatively easy to make thread-safe: protect the shared variables with synchronization operations such as P and V . An advantage is that it does not require any changes in the calling program. A disadvantage is that the synchronization operations will slow down the function. 解决方案，加锁。</p></li>
<li><p>Functions that keep state across multiple invocations. A pseudorandom number generator is a simple example of this class of thread-unsafe function. The rand function is thread-unsafe because the result of the current invocation depends on an intermediate result from the previous iteration. When we call rand repeatedly from a single thread after seeding it with a call to srand, we can expect a repeatable sequence of numbers. However, this assumption no longer holds if multiple threads are calling rand. The only way to make a function such as rand thread-safe is to rewrite it so that it does not use any static data, relying instead on the caller to pass the state information in arguments. The disadvantage is that the programmer is now forced to change the code in the calling routine as well. 解决方案是不用static，而是通过caller传参数。</p></li>
<li><p>Functions that return a pointer to a static variable. Some functions, such as ctime and gethostbyname, compute a result in a static variable and then return a pointer to that variable. If we call such functions from concurrent threads, then disaster is likely, as results being used by one thread are silently overwritten by another thread.</p></li>
<li><p>Functions that call thread-unsafe functions. If a function f calls a thread-unsafe function g, is f thread-unsafe? It depends. If g is a class 2 function that relies on state across multiple invocations, then f is also thread- unsafe and there is no recourse short of rewriting g. However, if g is a class 1 or class 3 function, then f can still be thread-safe if you protect the call site and any resulting shared data with a mutex. 一个调用了线程非安全函数的函数是否是线程安全的呢？ 这得看情况。</p></li>
</ul>


<p>Reentrancy 可重入性</p>

<p>There is an important class of thread-safe functions, known as reentrant functions, that are characterized by the property that they do not reference any shared data when they are called by multiple threads. 可重入函数是线程安全函数的子集，也就是说可重入函数一定是线程安全的，反之不成立。</p>

<p>Reentrant functions are typically more efficient than nonreentrant thread- safe functions because they require no synchronization operations.</p>

<p>Races  竞争</p>

<p>A race occurs when the correctness of a program depends on one thread reaching point x in its control flow before another thread reaches point y. Races usually occur because programmers assume that threads will take some particular trajec- tory through the execution state space, forgetting the golden rule that threaded programs must work correctly for any feasible trajectory.</p>

<p>The scary thing is that whether we get the correct answer depends on how the kernel sched- ules the execution of the threads. On our system it fails, but on other systems it might work correctly, leaving the programmer blissfully unaware of a serious bug. 此类bug不易复现，因而很难修复</p>

<p>Deadlocks 死锁</p>

<p>Semaphores introduce the potential for a nasty kind of run-time error, called deadlock, where a collection of threads are blocked, waiting for a condition that will never be true.</p>

<p>Deadlock is an especially difficult issue because it is not always predictable. Some lucky execution trajectories will skirt the deadlock region, while others will be trapped by it. The implications for a programmer are scary. You might run the same program 1000 times without any problem, but then the next time it deadlocks.Or the program might work fine on one machine but deadlock on another. Worst of all, the error is often not repeatable because different executions have different trajectories.</p>

		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2016/08/29/csapp-concurrent-programming//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2016/08/29/csapp-network-programming/">
		
			Csapp Network Programming</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2016-08-29T08:57:00+08:00" pubdate data-updated="true">Aug 29<span>th</span>, 2016</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<h3>The Client-Server Programming Model</h3>

<p>Every network application is based on the client-server model. With this model, an application consists of a server process and one or more client processes. A server manages some resource, and it provides some service for its clients by manipulating that resource.</p>

<h3>Networks</h3>

<p>Clients and servers often run on separate hosts and communicate using the hard- ware and software resources of a computer network.</p>

<p>To a host, <strong>a network is just another I/O device that serves as a source and sink for data.</strong> An adapter plugged into an expansion slot on the I/O bus provides the physical interface to the network. Data received from the network is copied from the adapter across the I/O and memory buses into memory, typically by a DMA transfer. Similarly, data can also be copied from memory to the network.</p>

<h3>The Socket Interface</h3>

<p>Internet clients and servers communicate by sending and receiving streams of bytes over connections. A connection is point-to-point in the sense that it connects a pair of processes. It is full-duplex in the sense that data can flow in both directions <strong>at the same time.</strong> And it is reliable in the sense that—barring some catastrophic failure such as a cable cut by the proverbial careless backhoe operator—the stream of bytes sent by the source process is eventually received by the destination process in the same order it was sent.</p>

<p>A socket is an end point of a connection. Each socket has a corresponding socket address that consists of an Internet address and a 16-bit integer port, and is denoted by address:port. The port in the client’s socket address is assigned automatically by the kernel when the client makes a connection request, and is known as an ephemeral port. However, the port in the server’s socket address is typically some well-known port that is associated with the service. For example, Web servers typically use port 80, and email servers use port 25. 客户端的端口是由内核自动指定的，服务器的端口是事先手动定义好的。</p>

<p>A connection is uniquely identified by the socket addresses of its two end-points. This pair of socket addresses is known as a socket pair. 一个connection由两端的socket唯一确定。</p>

<p>The sockets interface is a set of functions that are used in conjunction with the Unix I/O functions to build network applications.</p>

<h3>Web Servers</h3>

<p>Web clients and servers interact using a text-based application-level protocol known as HTTP (Hypertext Transfer Protocol). HTTP is a simple protocol. A Web client (known as a browser) opens an Internet connection to a server and requests some content. The server responds with the requested content and then closes the connection. The browser reads the content and displays it on the screen.</p>

<p>What distinguishes Web services from conventional file retrieval services such as FTP? The main difference is that Web content can be written in a language known as HTML (Hypertext Markup Language). An HTML program (page) contains instructions (tags) that tell the browser how to display various text and graphical objects in the page. HTTP服务跟其它web服务的区别</p>

<h4>Web Content</h4>

<p>To Web clients and servers, content is a sequence of bytes with an associated MIME (Multipurpose Internet Mail Extensions) type. Web servers provide content to clients in two different ways:</p>

<ul>
<li><p>Fetch a disk file and return its contents to the client. The disk file is known as static content and the process of returning the file to the client is known as serving static content.</p></li>
<li><p>Run an executable file and return its output to the client. The output produced by the executable at run time is known as dynamic content, and the process of running the program and returning its output to the client is known as serving dynamic content.</p></li>
</ul>


		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2016/08/29/csapp-network-programming//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2016/08/28/csapp-system-level-io/">
		
			Csapp System Level Io</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2016-08-28T16:42:00+08:00" pubdate data-updated="true">Aug 28<span>th</span>, 2016</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<h3>概览</h3>

<p>是什么？</p>

<p>Input/output (I/O) is the process of copying data between main memory and external devices such as disk drives, terminals, and networks. An input operation copies data from an I/O device to main memory, and an output operation copies data from memory to a device.</p>

<p>为什么？</p>

<p>All language run-time systems provide higher-level facilities for performing I/O. For example, ANSI C provides the standard I/O library, with functions such as printf and scanf that perform buffered I/O. The C++ language provides similar functionality with its overloaded &lt;&lt; (“put to”) and >> (“get from”) operators. On Unix systems, these higher-level I/O functions are implemented using system-level Unix I/O functions provided by the kernel. <strong>Most of the time, the higher-level I/O functions work quite well and there is no need to use Unix I/O directly. So why bother learning about Unix I/O?</strong></p>

<ul>
<li><p>Understanding Unix I/O will help you understand other systems concepts. I/O is integral to the operation of a system, and because of this we often encounter circular dependences between I/O and other systems ideas.</p></li>
<li><p>Sometimes you have no choice but to use Unix I/O. There are some important cases where using higher-level I/O functions is either impossible or inappro- priate. For example, the standard I/O library provides no way to access file metadata such as file size or file creation time. Further, there are problems with the standard I/O library that make it risky to use for network programming.</p></li>
</ul>


<h3>Unix I/O</h3>

<p>A Unix file is a sequence of m bytes.</p>

<p>All I/O devices, such as networks, disks, and terminals, are modeled as files, and all input and output is performed by reading and writing the appropriate files. This elegant mapping of devices to files allows the Unix kernel to export a simple, low-level application interface, known as Unix I/O, that enables all input and output to be performed in a uniform and consistent way. 所有的io设备都被抽象成文件，对设备的输入输出操作被抽象成对文件的读和写操作。</p>

<p>针对文件的基本操作：</p>

<ul>
<li>Opening files. An application announces its intention to access an I/O device by asking the kernel to open the corresponding file. The kernel returns a small nonnegative integer, called a descriptor, that identifies the file in all subsequent operations on the file. The kernel keeps track of all information about the open file. The application only keeps track of the descriptor.</li>
</ul>


<p>Each process created by a Unix shell begins life with three open files: standard input (descriptor 0), standard output (descriptor 1), and standard error (descriptor 2). The header file <code>&lt;unistd.h&gt;</code> defines constants <code>STDIN_ FILENO</code>, <code>STDOUT_FILENO</code>, and <code>STDERR_FILENO</code>, which can be used instead of the explicit descriptor values. 进程从出生自带三个打开的文件：标准输入、标准输出和标准错误输出。</p>

<ul>
<li><p>Changing the current file position. The kernel maintains a file position k, ini- tially 0, for each open file. The file position is a byte offset from the beginning of a file. An application can set the current file position k explicitly by per- forming a seek operation.</p></li>
<li><p>Reading and writing files. A read operation copies n > 0 bytes from a file to memory, starting at the current file position k, and then incrementing k by n. Given a file with a size of m bytes, performing a read operation when k ≥ m triggers a condition known as end-of-file (EOF), which can be detected by the application. There is no explicit “EOF character” at the end of a file. 在文件中并不存在EOF这个字符，EOF是由操作系统触发的。</p></li>
<li><p>Closing files. When an application has finished accessing a file, it informs the kernel by asking it to close the file. The kernel responds by freeing the data structures it created when the file was opened and restoring the descriptor to a pool of available descriptors. When a process terminates for any reason, the kernel closes all open files and frees their memory resources.</p></li>
</ul>


<p>读或者写函数有时候返回的字节数要比你要求的要少，这并不代表有错，出现这种情形的原因有以下几点(In some situations, read and write transfer fewer bytes than the application requests. Such short counts do not indicate an error. They occur for a number of reasons)：</p>

<ul>
<li><p>Encountering EOF on reads. Suppose that we are ready to read from a file that contains only 20 more bytes from the current file position and that we are reading the file in 50-byte chunks. Then the next read will return a short count of 20, and the read after that will signal EOF by returning a short count of zero. 读的时候碰到EOF了。</p></li>
<li><p>Reading text lines from a terminal. If the open file is associated with a terminal (i.e., a keyboard and display), then each read function will transfer one text line at a time, returning a short count equal to the size of the text line(A text line is a sequence of ASCII characters terminated by a newline character.). 从终端读的时候，是按行返回的，用户输入了几个字符就会返回几个。</p></li>
<li><p>Reading and writing network sockets. If the open file corresponds to a network socket (Section 11.3.3), then internal buffering constraints and long network delays can cause read and write to return short counts. Short counts can also occur when you call read and write on a Unix pipe, an interprocess communication mechanism that is beyond our scope. 从socket返回时，由于buffer或者网络延迟。</p></li>
</ul>


<p>In practice, you will never encounter short counts when you read from disk files except on EOF, and you will never encounter short counts when you write to disk files. However, if you want to build robust (reliable) network applications such as Web servers, then you must deal with short counts by repeatedly calling read and write until all requested bytes have been transferred. 实际在从硬盘文件中读的时候，除了碰到EOF其它时候都不应该遇到返回字节数少的情况；在往硬盘文件中写的时候，任何时候都不应该出现这种情况。</p>

		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2016/08/28/csapp-system-level-io//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>


    <article class="post">
	<h2 class="title">
		
		<a href="/blog/2016/08/26/csapp-exceptional-control-flow/">
		
			Csapp Exceptional Control Flow</a>
	</h2>
    <div class="entry-content">
    <div class="meta">
      <div class="date">Published on: 








  


<time datetime="2016-08-26T12:08:00+08:00" pubdate data-updated="true">Aug 26<span>th</span>, 2016</time></div>
      <div class="tags">Tags: 

</div>
    </div>
		<h3>Chapter 8 Exceptional Control Flow</h3>

<p>从一上电开始，CPU就在不停得执行指令，从第k个指令转到k+1个指令执行，叫做指令转移(control transfer)，一堆指令转移的集合就叫控制流(flow of control or control flow of the process)。</p>

<p>最简单的控制流就是一条接着一条的执行，只要执行的指令在内存中都是毗邻的，不需要跳转。当然，由于程序逻辑上的一些需求（比如分支、函数调用、调用返回）不可避免的会产生跳转。</p>

<p>但还有其它一些跳转需求，是跟程序内部执行逻辑无关的，比如硬件时钟、磁盘IO、创建子进程等(a hardware timer goes off at regular intervals and must be dealt with. Packets arrive at the network adapter and must be stored in memory. Programs request data from a disk and then sleep until they are notified that the data are ready. Parent processes that create child processes must be notified when their children terminate.) 对于这些情形，现代操作系统也是通过跳转来应对的。这些跳转被统称为exceptional control flow (ECF). ECF可以发生在一个计算机系统的各个层面，比如硬件层面、操作系统层面、应用程序层面等。(Exceptional control flow occurs at all levels of a computer system. For example, at the hardware level, events detected by the hardware trigger abrupt control transfers to exception handlers. At the operating systems level, the kernel transfers control from one user process to another via context switches. At the application level, a process can send a signal to another process that abruptly transfers control to a signal handler in the recipient. An individual program can react to errors by sidestepping the usual stack discipline and making nonlocal jumps to arbitrary locations in other functions)</p>

<p>那为什么要理解ECF呢？</p>

<ul>
<li>有助于理解重要的操作系统概念。ECF is the basic mechanism that operating systems use to implement I/O, processes, and virtual memory. Before you can really understand these important ideas, you need to understand ECF.</li>
<li>有助于理解应用程序是如何跟操作系统交互的。Applications request services from the operating system by using a form of ECF known as a trap or system call. For example, writing data to a disk, reading data from a network, creating a new process, and terminating the current process are all accomplished by application programs invoking system calls. Understanding the basic system call mechanism will help you understand how these services are provided to applications.</li>
<li>有助于理解并发(concurrency)。ECF is a basic mechanism for implementing concurrency in computer systems. An exception handler that interrupts the execution of an application program, processes and threads whose execution overlap in time, and a signal handler that interrupts the execution of an application program are all examples of concurrency in action. Understanding ECF is a first step to understanding concurrency.
有助于理解软件层面的异常(software exceptions)是如何工作的。Languages such as C++ and Java provide software exception mechanisms via try, catch, and throw statements. Software exceptions allow the program to make nonlocal jumps (i.e., jumps that violate the usual call/return stack discipline) in response to error conditions. Nonlocal jumps are a form of application-level ECF, and are provided in C via the setjmp and longjmp functions. Understanding these low-level functions will help you understand how higher-level software exceptions can be implemented.</li>
</ul>


<h4>8.1 Exceptions</h4>

<p>异常部分是由硬件实现的，部分是由操作系统实现的(Exceptions are a form of exceptional control flow that are implemented partly by the hardware and partly by the operating system.)。</p>

<p>An exception is an abrupt change in the control flow in response to some change in the processor’s state. The change in state is known as an event. The event might be directly related to the execution of the current instruction. For example, a virtual memory page fault occurs, an arithmetic overflow occurs, or an instruction attempts a divide by zero. On the other hand, the event might be unrelated to the execution of the current instruction. For example, a system timer goes off or an I/O request completes.（状态的改变我们称之为事件，事件可能跟正在执行的指令相关，比如内存页错误；也可能与当前执行的指令不相干，比如CPU时间到了。）</p>

<p>不管是哪种情况，都会跳到对应的异常处理程序那里执行。(In any case, when the processor detects that the event has occurred, it makes an indirect procedure call (the exception), through a jump table called an exception table, to an operating system subroutine (the exception handler) that is specifically designed to process this particular kind of event.)</p>

<p>异常处理程序处理完以后，可能会发生以下三种情况的一种：</p>

<ul>
<li>The handler returns control to the current instruction Icurr, the instruction that was executing when the event occurred.</li>
<li>The handler returns control to Inext, the instruction that would have executed next had the exception not occurred.</li>
<li>The handler aborts the interrupted program.</li>
</ul>


<h5>Classes of Exceptions</h5>

<p>异常可以被分为4类：interrupts, traps, faults, and aborts.
&ndash; Interrupts</p>

<p>Interrupts occur asynchronously as a result of signals from I/O devices that are external to the processor. Hardware interrupts are asynchronous in the sense that they are not caused by the execution of any particular instruction. Exception handlers for hardware interrupts are often called interrupt handlers.</p>

<p>这里讲到的asynchronous和synchronous的意思：Asynchronous exceptions occur as a result of events in I/O devices that are external to the processor. Synchronous exceptions occur as a direct result of executing an instruction.</p>

<p>interrupt的处理过程：</p>

<p>I/O devices such as network adapters, disk controllers, and timer chips trigger interrupts by signaling a pin on the processor chip and placing onto the system bus the exception number that identifies the device that caused the interrupt.</p>

<p>After the current instruction finishes executing, the processor notices that the interrupt pin has gone high, reads the exception number from the system bus, and then calls the appropriate interrupt handler. When the handler returns, it returns control to the next instruction (i.e., the instruction that would have followed the current instruction in the control flow had the interrupt not occurred). The effect is that the program continues executing as though the interrupt had never happened.</p>

<ul>
<li>Traps and System Calls</li>
</ul>


<p>Traps</p>

<p>Traps are intentional exceptions that occur as a result of executing an instruction. Like interrupt handlers, trap handlers return control to the next instruction. The most important use of traps is to provide a procedure-like interface between user programs and the kernel known as a system call.</p>

<p>User programs often need to request services from the kernel such as reading a file (read), creating a new process (fork), loading a new program (execve), or terminating the current process (exit). To allow controlled access to such kernel services, processors provide a special “syscall n” instruction that user programs can execute when they want to request service n. Executing the syscall instruction causes a trap to an exception handler that decodes the argument and calls the appropriate kernel routine.</p>

<p>From a programmer’s perspective, a system call is identical to a regular function call. However, their implementations are quite different. Regular functions run in user mode, which restricts the types of instructions they can execute, and they access the same stack as the calling function. A system call runs in kernel mode, which allows it to execute instructions, and accesses a stack defined in the kernel.</p>

<p>Faults</p>

<p>Faults result from error conditions that a handler might be able to correct. When a fault occurs, the processor transfers control to the fault handler. If the handler is able to correct the error condition, it returns control to the faulting instruction, thereby reexecuting it. Otherwise, the handler returns to an abort routine in the kernel that terminates the application program that caused the fault. 出现Fault后，要么经Fault handler处理后，原来的指令重新跑；要么直接Abort程序。</p>

<p>A classic example of a fault is the page fault exception, which occurs when an instruction references a virtual address whose corresponding physical page is not resident in memory and must therefore be retrieved from disk. As we will see in Chapter 9, a page is a contiguous block (typically 4 KB) of virtual memory. The page fault handler loads the appropriate page from disk and then returns control to the instruction that caused the fault. When the instruction executes again, the appropriate physical page is resident in memory and the instruction is able to run to completion without faulting.</p>

<p>Aborts</p>

<p>Aborts result from unrecoverable fatal errors, typically hardware errors such as parity errors that occur when DRAM or SRAM bits are corrupted. Abort handlers never return control to the application program. The handler returns control to an abort routine that terminates the application program. Abort handler不会把控制权返回给应用程序了。</p>

<h4>Processes 进程</h4>

<p>Exceptions are the basic building blocks that allow the operating system to provide the notion of a process, one of the most profound and successful ideas in computer science. 有了异常才能谈进程，异常机制是操作系统实现进程的基础。</p>

<p>When we run a program on a modern system, we are presented with the illusion that our program is the only one currently running in the system. Our program appears to have exclusive use of both the processor and the memory. The processor appears to execute the instructions in our program, one after the other, without interruption. Finally, the code and data of our program appear to be the only objects in the system’s memory. These illusions are provided to us by the notion of a process. 进程是个抽象概念。</p>

<p>Each program in the system runs in the context of some process. The context consists of the state that the program needs to run correctly. This state includes <strong>the program’s code and data stored in memory, its stack, the contents of its general- purpose registers, its program counter, environment variables, and the set of open file descriptors.</strong> 解释了进程上下文都包括哪些东西。</p>

<p>进程给应用程序提供了两个关键抽象：</p>

<blockquote><p>An independent logical control flow that provides the illusion that our pro- gram has exclusive use of the processor.</p>

<p>A private address space that provides the illusion that our program has exclu- sive use of the memory system.</p></blockquote>

<p>Logical Control Flow</p>

<p>The single physical control flow of the processor is partitioned into logical flows, one for each process.</p>

<p>Concurrent Flows</p>

<p>A logical flow whose execution overlaps in time with another flow is called a concurrent flow, and the two flows are said to run concurrently. More precisely, flows X and Y are concurrent with respect to each other if and only if X begins after Y begins and before Y finishes, or Y begins after X begins and before X finishes.  并发并不是我们平常理解的那个意思，只要两个进程的逻辑流的执行时间有重叠，就算并发了。</p>

<p>Notice that the idea of concurrent flows is independent of the number of processor cores or computers that the flows are running on. If two flows overlap in time, then they are concurrent, even if they are running on the same processor. However, we will sometimes find it useful to identify a proper subset of concurrent flows known as parallel flows. If two flows are running concurrently on different processor cores or computers, then we say that they are parallel flows, that they are running in parallel, and have parallel execution. 解了我许久的一个困惑，那就是并发和并行到底是什么意思？？这里讲的就很清楚了，并发(concurrency)跟CPU核数是无关的，它只跟逻辑流的执行时间有关系，只要两个进程逻辑流的执行时间有重叠，那么他们就是并发的，即使它们是运行在同一个核上。并行(parallel)是并发的子集了，就是说，如果两个进程已经是并发了，而且还是运行在不同的核上或计算机上，那它们就是并行的了。</p>

<p>Private Address Space 私有内存空间</p>

<p>A process provides each program with its own private address space. This space is private in the sense that a byte of memory associated with a particular address in the space cannot in general be read or written by any other process.</p>

<p>User and Kernel Modes 用户模式和内核模式</p>

<p>In order for the operating system kernel to provide an airtight process abstraction, the processor must provide a mechanism that restricts the instructions that an application can execute, as well as the portions of the address space that it can access.</p>

<p>Processors typically provide this capability with a mode bit in some control register that characterizes the privileges that the process currently enjoys. When the mode bit is set, the process is running in kernel mode (sometimes called supervisor mode). A process running in kernel mode can execute any instruction in the instruction set and access any memory location in the system.</p>

<p>When the mode bit is not set, the process is running in user mode. A process in user mode is not allowed to execute privileged instructions that do things such as halt the processor, change the mode bit, or initiate an I/O operation. Nor is it allowed to directly reference code or data in the kernel area of the address space. Any such attempt results in a fatal protection fault. User programs must instead access kernel code and data indirectly via the system call interface.</p>

<p>A process running application code is initially in user mode. The only way for the process to change from user mode to kernel mode is via an exception such as an interrupt, a fault, or a trapping system call. When the exception occurs, and control passes to the exception handler, the processor changes the mode from user mode to kernel mode. The handler runs in kernel mode. When it returns to the application code, the processor changes the mode from kernel mode back to user mode.</p>

<p>Context Switches 上下文切换</p>

<p>The operating system kernel implements multitasking using a higher-level form of exceptional control flow known as a context switch. The context switch mecha- nism is built on top of the lower-level exception mechanism. 上下文切换也是基于异常做的。</p>

<p>The kernel maintains a context for each process. The context is the state that the kernel needs to restart a preempted process. It consists of the values of objects such as the general purpose registers, the floating-point registers, the program counter, user’s stack, status registers, kernel’s stack, and various kernel data structures such as a page table that characterizes the address space, a process table that contains information about the current process, and a file table that contains information about the files that the process has opened.</p>

<p>At certain points during the execution of a process, the kernel can decide to preempt the current process and restart a previously preempted process. This decision is known as scheduling, and is handled by code in the kernel called the scheduler. When the kernel selects a new process to run, we say that the kernel has scheduled that process. After the kernel has scheduled a new process to run, it preempts the current process and transfers control to the new process using a mechanism called a context switch that (1) saves the context of the current process, (2) restores the saved context of some previously preempted process, and (3) passes control to this newly restored process.</p>

<p>A context switch can occur while the kernel is executing a system call on behalf of the user. If the system call blocks because it is waiting for some event to occur, then the kernel can put the current process to sleep and switch to another process. For example, if a read system call requires a disk access, the kernel can opt to perform a context switch and run another process instead of waiting for the data to arrive from the disk. Another example is the sleep system call, which is an explicit request to put the calling process to sleep. In general, even if a system call does not block, the kernel can decide to perform a context switch rather than return control to the calling process.</p>

<p>A context switch can also occur as a result of an interrupt. For example, all systems have some mechanism for generating periodic timer interrupts, typically every 1 ms or 10 ms. Each time a timer interrupt occurs, the kernel can decide that the current process has run long enough and switch to a new process.</p>

<p>Creating and Terminating Processes 进程的创建和销毁</p>

<p>From a programmer’s perspective, we can think of a process as being in one of three states，进程的三种状态：</p>

<blockquote><p>Running. The process is either executing on the CPU or is waiting to be executed and will eventually be scheduled by the kernel. 注意这个running不一定是说正在跑，只是一个可调度的状态，叫ready更好一点。</p>

<p>Stopped. The execution of the process is suspended and will not be scheduled. A process stops as a result of receiving a SIGSTOP, SIGTSTP, SIGTTIN, or SIGTTOU signal, and it remains stopped until it receives a SIGCONT signal, at which point it can begin running again. 不可调度状态，暂停了，但还能恢复</p>

<p>Terminated. The process is stopped permanently. A process becomes termi- nated for one of three reasons: (1) receiving a signal whose default action is to terminate the process, (2) returning from the main routine, or (3) calling the exit function  永久结束了</p></blockquote>

<p>Fork</p>

<p>A parent process creates a new running child process by calling the fork function. fork有以下特点：</p>

<pre><code>#include "csapp.h"

int main()
{
    pid_t pid;
    int x = 1;

    pid = Fork(); if(pid==0){ /*Child*/
        printf("child : x=%d\n", ++x);
        exit(0); }
    /* Parent */
    printf("parent: x=%d\n", --x);
    exit(0); }
}

output:
unix&gt; ./fork 
parent: x=0 
child : x=2
</code></pre>

<blockquote><p>Call once, return twice. The fork function is called once by the parent, but it returns twice: once to the parent and once to the newly created child. This is fairly straightforward for programs that create a single child. But programs with multiple instances of fork can be confusing and need to be reasoned about carefully.</p>

<p>Concurrent execution. The parent and the child are separate processes that run concurrently. The instructions in their logical control flows can be inter- leaved by the kernel in an arbitrary way. When we run the program on our system, the parent process completes its printf statement first, followed by the child. However, on another system the reverse might be true. In general, as programmers we can never make assumptions about the interleaving of the instructions in different processes.</p>

<p>Duplicate but separate address spaces. If we could halt both the parent and the child immediately after the fork function returned in each process, we would see that the address space of each process is identical. Each process has the same user stack, the same local variable values, the same heap, the same global variable values, and the same code. Thus, in our example program, local variable x has a value of 1 in both the parent and the child when the fork function returns in line 8. However, since the parent and the child are separate processes, they each have their own private address spaces. Any subsequent changes that a parent or child makes to x are private and are not reflected in the memory of the other process. This is why the variable x has different values in the parent and child when they call their respective printf statements.</p>

<p>Shared files. When we run the example program, we notice that both parent and child print their output on the screen. The reason is that the child inherits all of the parent’s open files. When the parent calls fork, the stdout file is open and directed to the screen. The child inherits this file and thus its output is also directed to the screen.</p></blockquote>

<p>Reaping Child Processes</p>

<p>When a process terminates for any reason, the kernel does not remove it from the system immediately. Instead, the process is kept around in a terminated state until it is reaped by its parent. When the parent reaps the terminated child, the kernel passes the child’s exit status to the parent, and then discards the terminated process, at which point it ceases to exist. A terminated process that has not yet been reaped is called a zombie. 已经是terminated状态但还没有被reaped的process叫僵尸程序</p>

<p>If the parent process terminates without reaping its zombie children, the kernel arranges for the init process to reap them. The init process has a PID of 1 and is created by the kernel during system initialization. Long-running programs such as shells or servers should always reap their zombie children. Even though zombies are not running, they still consume system memory resources. 父进程没收割的僵尸process会被init进程代为收割。</p>

<h4>Signals 信号</h4>

<p>A signal is a small message that notifies a process that an event of some type has occurred in the system.</p>

<p>Each signal type corresponds to some kind of system event. <strong>Low-level hard-ware exceptions are processed by the kernel’s exception handlers and would not normally be visible to user processes. Signals provide a mechanism for exposing the occurrence of such exceptions to user processes.</strong> For example, if a process attempts to divide by zero, then the kernel sends it a SIGFPE signal (number 8). If a process executes an illegal instruction, the kernel sends it a SIGILL signal (number 4). If a process makes an illegal memory reference, the kernel sends it a SIGSEGV signal (number 11). Other signals correspond to higher-level soft- ware events in the kernel or in other user processes. For example, if you type a ctrl-c (i.e., press the ctrl key and the c key at the same time) while a process is running in the foreground, then the kernel sends a SIGINT (number 2) to the foreground process. A process can forcibly terminate another process by sending it a SIGKILL signal (number 9). When a child process terminates or stops, the kernel sends a SIGCHLD signal (number 17) to the parent. 信号为底层硬件异常与应用程序之间搭了一座桥梁。</p>

<p>信号的发和收</p>

<blockquote><p>Sending a signal. The kernel sends (delivers) a signal to a destination process by updating some state in the context of the destination process. The signal is delivered for one of two reasons: (1) The kernel has detected a system event such as a divide-by-zero error or the termination of a child process. (2) A process has invoked the kill function (discussed in the next section) to explicitly request the kernel to send a signal to the destination process. A process can send a signal to itself.</p>

<p>Receiving a signal. A destination process receives a signal when it is forced by the kernel to react in some way to the delivery of the signal. The process can either ignore the signal, terminate, or catch the signal by executing a user-level function called a signal handler. Receipt of a signal triggers a control transfer to a signal handler. After it finishes processing, the handler returns control to the interrupted program. 接收信号也会打断正常的逻辑流。</p></blockquote>

<p>A signal that has been sent but not yet received is called a pending signal. At any point in time, there can be <strong>at most one pending signal of a particular type.</strong> If a process has a pending signal of type k, then any subsequent signals of type k sent to that process are not queued; <strong>they are simply discarded.</strong></p>

<p>A process can selectively <strong>block the receipt of certain signals.</strong> When a signal is blocked, it can be delivered, but the resulting pending signal will not be received until the process unblocks the signal. For each process, the kernel maintains the set of pending signals in the <strong>pending bit vector</strong>, and the set of blocked signals in the <strong>blocked bit vector</strong>. The kernel sets bit k in pending whenever a sig- nal of type k is delivered and clears bit k in pending whenever a signal of type k is received.</p>

<p>进程接收信号的流程</p>

<p>When the kernel is returning from an exception handler and is ready to pass control to process p, it checks the set of unblocked pending signals (pending &amp; ~blocked) for process p. If this set is empty (the usual case), then the kernel passes control to the next instruction (Inext) in the logical control flow of p.</p>

<p>However, if the set is nonempty, then the kernel chooses some signal k in the set (typically the smallest k) and forces p to receive signal k. The receipt of the signal triggers some action by the process. Once the process completes the action, then control passes back to the next instruction (Inext ) in the logical control flow of p. Each signal type has a predefined default action, which is one of the following: 1) The process terminates. 2) The process terminates and dumps core. 3) The process stops until restarted by a SIGCONT signal. 4) The process ignores the signal. 一般收到信号后的默认行为是可以改的，但SIGSTOP和SIGKILL是不允许改的。</p>

<p>Signal Handling Issues 信号处理存在的问题</p>

<blockquote><p>Pending signals are blocked. Unix signal handlers typically block pending signals of the type currently being processed by the handler. For example, suppose a process has caught a SIGINT signal and is currently running its SIGINT handler. If another SIGINT signal is sent to the process, then the SIGINT will become pending, but will not be received until after the handler returns. 在等待的信号会被阻塞住，要等前面的信号处理完才能处理它。</p>

<p>Pending signals are not queued. There can be at most one pending signal of any particular type. Thus, if two signals of type k are sent to a destination process while signal k is blocked because the destination process is currently executing a handler for signal k, then the second signal is simply discarded; it is not queued. The key idea is that the existence of a pending signal merely indicates that at least one signal has arrived. 最多只能pending一个信号，再多的信号就直接被抛弃了。</p>

<p>System calls can be interrupted. System calls such as read, wait, and accept that can potentially block the process for a long period of time are called slow system calls. On some systems, slow system calls that are interrupted when a handler catches a signal do not resume when the signal handler returns, but instead return immediately to the user with an error condition and errno set to EINTR. 当收到信号后，就算系统调用也会被打断，关键是在某些系统上被打断的系统调用在signal handler返回后不会自动重启。</p></blockquote>

<p>Explicitly Blocking and Unblocking Signals  显式block和unblock信号</p>

<p>Applications can explicitly block and unblock selected signals using the sigproc- mask function, The sigprocmask function changes the set of currently blocked signals.</p>

<p>Synchronizing Flows to Avoid Nasty Concurrency Bugs</p>

<p>并发容易引发bug, 并且很难定位。</p>

<p>The problem of how to program concurrent flows that read and write the same storage locations has challenged generations of computer scientists. In general,<strong>the number of potential interleavings of the flows is exponential in the number of instructions. Some of those interleavings will produce correct answers, and others will not.</strong> The fundamental problem is to somehow synchronize the concurrent flows so as to allow the largest set of feasible interleavings such that each of the feasible interleavings produces a correct answer.</p>

<p>Such errors are enormously difficult to debug because it is often impossible to test every interleaving. You may run the code a billion times without a problem, but then the next test results in an interleaving that triggers the race.</p>

<h4>Nonlocal Jumps</h4>

<p>C provides a form of user-level exceptional control flow, called a nonlocal jump, that transfers control directly from one function to another currently executing function without having to go through the normal call-and-return sequence. Non- local jumps are provided by the setjmp and longjmp functions.</p>

<p>The setjmp function saves the current calling environment in the env buffer, for later use by longjmp, and returns a 0. The calling environment includes the program counter, stack pointer, and general purpose registers.</p>

<p>The longjmp function restores the calling environment from the env buffer and then triggers a return from the most recent setjmp call that initialized env. The setjmp then returns with the nonzero return value retval.</p>

<p>The interactions between setjmp and longjmp can be confusing at first glance. The setjmp function is called once, but returns multiple times: once when the setjmp is first called and the calling environment is stored in the env buffer, and once for each corresponding longjmp call. On the other hand, the longjmp function is called once, but never returns.  调用关系确实有点乱啊。</p>

<p>An important application of nonlocal jumps is to permit an immediate return from a deeply nested function call, usually as a result of detecting some error condition. If an error condition is detected deep in a nested function call, we can use a nonlocal jump to return directly to a common localized error handler instead of laboriously unwinding the call stack.  应用之一：从很深的调用嵌套中直接跳到表层，而不是一层一层的解嵌套跳出(unwind the entire stack)。</p>

<p>Another important application of nonlocal jumps is to branch out of a signal handler to a specific code location, rather than returning to the instruction that was interrupted by the arrival of the signal. 应用之一：从signal handler里跳出来。</p>

<p>The exception mechanisms provided by C++ and Java are higher-level, more-structured versions of the C setjmp and longjmp functions. You can think of a catch clause inside a try statement as being akin to a setjmp function. Similarly, a throw statement is similar to a longjmp function. C++和Java中的exception是基于setjmp和longjmp实现的。</p>

		
		
	</div>

<div class="meta">
	
		<span class="comments"><a href="/blog/2016/08/26/csapp-exceptional-control-flow//blog/page/2/index.html#disqus_thread">Comments</a></span>
	
</div>
</article>

<nav id="pagenavi">
    
        <a href="/" class="prev">Prev</a>
    
    
        <a href="/blog/page/3/" class="next">Next</a>
    
    <div class="center"><a href="/blog/archives">Blog Archives</a></div>
</nav>

    </div>
    <footer id="footer">
    <div style="display:inline">
    Copyright &copy; 2020

    linuxfish
. Powered by <a href="http://octopress.org">Octopress</a> | 
    Theme <a href="http://github.com/panks/fabric">fabric</a> by <a href="http://panks.me">Pankaj Kumar</a>
</div>


    </footer>
    <script src="/javascripts/fabric.js"></script>
<script src="/javascripts/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
	$('.fancybox').fancybox();
})(jQuery);
</script> <!-- Delete or comment this line to disable Fancybox -->


<script type="text/javascript">
      var disqus_shortname = 'thehardwayiseasier';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>





<!-- end toload --> 
</div>
</div>
<script src="/javascripts/jquery.ui.totop.js" type="text/javascript"></script>
<script type="text/javascript">
/*<![CDATA[*/
;(function($){$().UItoTop({easingType:'easeOutCirc'});})(jQuery); 
/*]]>*/
</script><!-- remove it to remove the scroll to top button -->
</body>
</html>
